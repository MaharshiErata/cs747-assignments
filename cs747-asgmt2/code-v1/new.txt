import argparse

def parse_testcases(filename):
    """Parse test case file into list of grids"""
    testcases = []
    current = []
    with open(filename) as f:
        for line in f:
            line = line.strip()
            if line.startswith("Testcase"):
                if current:
                    testcases.append(current)
                    current = []
            elif line:
                current.append(line.split())
    if current:
        testcases.append(current)
    return testcases

def determine_structure(testcases):
    """Identify walls, door, key from all test cases"""
    walls = set()
    doors = set()
    keys = set()
    size = len(testcases[0]) if testcases else 0
    for grid in testcases:
        for x in range(size):
            for y in range(size):
                cell = grid[x][y]
                if cell == 'W':
                    walls.add((x, y))
                elif cell == 'd':
                    doors.add((x, y))
                elif cell == 'k':
                    keys.add((x, y))
    door = next(iter(doors), None)
    key = next(iter(keys), None)
    return walls, door, key, size

def build_state_list(walls, door, key, size):
    """Replicate encoder's state enumeration order"""
    states = []
    for x in range(size):
        for y in range(size):
            if (x, y) in walls:
                continue  # Skip walls
            if (x, y) == door:
                # Door cells: only has_key=1
                for dir in range(4):
                    states.append((x, y, dir, 1))
            else:
                # Regular cells: both key states
                for has_key in [0, 1]:
                    for dir in range(4):
                        states.append((x, y, dir, has_key))
    return states

def get_agent_state(grid, key_pos):
    """Extract agent's state from grid"""
    size = len(grid)
    x, y, dir = -1, -1, -1
    has_key = 0
    # Check if key exists in this grid
    key_present = any('k' in row for row in grid)
    if not key_present and key_pos:
        has_key = 1  # Key collected
    # Find agent position/direction
    for i in range(size):
        for j in range(size):
            cell = grid[i][j]
            if cell in ['^', '>', 'v', '<']:
                dir = {'^':0, '>':1, 'v':2, '<':3}[cell]
                x, y = i, j
    return (x, y, dir, has_key)

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--mdp', required=True)
    parser.add_argument('--value-policy', required=True)
    parser.add_argument('--gridworld', required=True)
    args = parser.parse_args()

    testcases = parse_testcases(args.gridworld)
    if not testcases:
        print("0")
        return

    # Determine static environment structure
    walls, door, key, size = determine_structure(testcases)
    states = build_state_list(walls, door, key, size)
    state_to_idx = {s:i for i, s in enumerate(states)}

    # Load policy
    with open(args.value_policy) as f:
        policy = [int(line.split()[1]) for line in f if line.strip()]

    # Process each test case
    actions = []
    for grid in testcases:
        state = get_agent_state(grid, key)
        # Validate state
        if state[0] == -1 or (state[0], state[1]) in walls:
            actions.append(0)
            continue
        # Get action from policy
        idx = state_to_idx.get(state, -1)
        actions.append(policy[idx] if 0 <= idx < len(policy) else 0)

    print(' '.join(map(str, actions)))

if __name__ == "__main__":
    main()


























# import argparse

# def parse_testcase_file(filename):
#     testcases = []
#     current_grid = []
#     with open(filename, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if line.startswith("Testcase"):
#                 if current_grid:
#                     testcases.append(current_grid)
#                     current_grid = []
#             elif line:
#                 current_grid.append(line.split())
#     if current_grid:
#         testcases.append(current_grid)
#     return testcases

# def determine_grid_structure(testcases):
#     walls = set()
#     door_pos = None
#     key_pos = None
#     size = len(testcases[0]) if testcases else 0

#     # Aggregate positions from all test cases
#     all_door = set()
#     all_key = set()
#     all_walls = set()

#     for grid in testcases:
#         for x in range(size):
#             for y in range(size):
#                 cell = grid[x][y]
#                 if cell == 'W':
#                     all_walls.add((x, y))
#                 elif cell == 'd':
#                     all_door.add((x, y))
#                 elif cell == 'k':
#                     all_key.add((x, y))

#     # Walls are cells that are 'W' in ALL grids
#     walls = set()
#     for x in range(size):
#         for y in range(size):
#             if all((x, y) in all_walls for grid in testcases):
#                 walls.add((x, y))

#     # Door/key position is the one that appears in ANY grid
#     door_pos = next(iter(all_door), None) if all_door else None
#     key_pos = next(iter(all_key), None) if all_key else None

#     return walls, door_pos, key_pos, size

# def get_agent_state(grid, key_pos):
#     size = len(grid)
#     x, y, dir = -1, -1, -1
#     has_key = 0
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell in ['>', '<', '^', 'v']:
#                 dir = {'^': 0, '>': 1, 'v': 2, '<': 3}[cell]
#                 x, y = i, j
#             if cell == 'k':
#                 has_key = 0  # Key present in grid => not collected
#     if key_pos and (x, y) == key_pos:
#         has_key = 1  # Agent is on key's original position
#     return (x, y, dir, has_key)

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     testcases = parse_testcase_file(args.gridworld)
#     if not testcases:
#         print("0")
#         return

#     walls, door_pos, key_pos, size = determine_grid_structure(testcases)

#     # Replicate encoder's state enumeration
#     states = []
#     for x in range(size):
#         for y in range(size):
#             if (x, y) in walls:
#                 continue
#             # Door cells only allow has_key=1
#             if (x, y) == door_pos:
#                 for dir in range(4):
#                     states.append((x, y, dir, 1))
#             else:
#                 for has_key in [0, 1]:
#                     for dir in range(4):
#                         states.append((x, y, dir, has_key))
#     state_id = {state: idx for idx, state in enumerate(states)}

#     # Load policy
#     with open(args.value_policy, 'r') as f:
#         policy = []
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))
#             else:
#                 policy.append(0)

#     # Process each test case
#     actions = []
#     for grid in testcases:
#         x, y, dir, hk = get_agent_state(grid, key_pos)
#         if (x, y) in walls or (x, y) == (-1, -1):
#             actions.append(0)
#             continue
#         current_state = (x, y, dir, hk)
#         state_idx = state_id.get(current_state, -1)
#         if 0 <= state_idx < len(policy):
#             actions.append(policy[state_idx])
#         else:
#             actions.append(0)

#     print(' '.join(map(str, actions)))

# if __name__ == "__main__":
#     main()

























# import argparse

# def parse_testcase_file(filename):
#     testcases = []
#     current_grid = []
#     with open(filename, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if line.startswith("Testcase"):
#                 if current_grid:
#                     testcases.append(current_grid)
#                     current_grid = []
#             elif line:
#                 current_grid.append(line.split())
#     if current_grid:
#         testcases.append(current_grid)
#     return testcases

# def get_agent_state(grid):
#     size = len(grid)
#     x, y, direction = -1, -1, -1
#     key_present = False
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell in ['>', '<', '^', 'v']:
#                 direction = {'^': 0, '>': 1, 'v': 2, '<': 3}[cell]
#                 x, y = i, j
#             if cell == 'k':
#                 key_present = True
#     has_key = not key_present  # Key collected if not present in grid
#     return (x, y, direction, 1 if has_key else 0)

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     # Parse test cases and extract static grid structure from the first test case
#     testcases = parse_testcase_file(args.gridworld)
#     if not testcases:
#         print("0")
#         return
#     static_grid = testcases[0]
#     size = len(static_grid)

#     # Replicate encoder's state enumeration logic
#     door_pos = None
#     key_pos = None
#     goal_pos = None
#     for i in range(size):
#         for j in range(size):
#             cell = static_grid[i][j]
#             if cell == 'd':
#                 door_pos = (i, j)
#             elif cell == 'k':
#                 key_pos = (i, j)
#             elif cell == 'g':
#                 goal_pos = (i, j)

#     states = []
#     for x in range(size):
#         for y in range(size):
#             cell = static_grid[x][y]
#             if cell == 'W':
#                 continue  # Skip walls
#             # Door cells only have states with has_key=1
#             if (x, y) == door_pos:
#                 for dir in range(4):
#                     states.append((x, y, dir, 1))
#             else:
#                 for has_key in [0, 1]:
#                     for dir in range(4):
#                         states.append((x, y, dir, has_key))
#     state_id = {state: idx for idx, state in enumerate(states)}

#     # Load policy ensuring alignment with states
#     with open(args.value_policy, 'r') as f:
#         policy = []
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))
#             else:
#                 policy.append(0)  # Handle malformed lines

#     # Process each test case grid
#     actions = []
#     for grid in testcases:
#         x, y, dir, hk = get_agent_state(grid)
#         # Check if position is valid (not a wall)
#         if static_grid[x][y] == 'W':
#             actions.append(0)
#             continue
#         current_state = (x, y, dir, hk)
#         state_idx = state_id.get(current_state, -1)
#         if state_idx == -1 or state_idx >= len(policy):
#             actions.append(0)
#         else:
#             actions.append(policy[state_idx])

#     print(' '.join(map(str, actions)))

# if __name__ == "__main__":
#     main()















# import argparse

# def parse_testcase_file(filename):
#     testcases = []
#     current_grid = []
#     with open(filename, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if line.startswith("Testcase"):
#                 if current_grid:
#                     testcases.append(current_grid)
#                     current_grid = []
#             elif line:
#                 current_grid.append(line.split())
#     if current_grid:
#         testcases.append(current_grid)
#     return testcases

# def get_agent_state(grid):
#     size = len(grid)
#     x, y, direction = -1, -1, -1
#     key_present = False
#     door_pos = None
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell in ['>', '<', '^', 'v']:
#                 direction = {'^':0, '>':1, 'v':2, '<':3}[cell]
#                 x, y = i, j
#             if cell == 'k':
#                 key_present = True
#             if cell == 'd':
#                 door_pos = (i, j)
#     has_key = not key_present
#     return (x, y, direction, 1 if has_key else 0)

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     testcases = parse_testcase_file(args.gridworld)
#     if not testcases:
#         print("0")
#         return

#     # Replicate encoder's state enumeration logic
#     grid = testcases[0]  # Use first grid to build states (walls are consistent)
#     size = len(grid)
#     states = []
#     door_pos = None
#     key_pos = None
#     goal_pos = None

#     # Find special positions
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell == 'd':
#                 door_pos = (i, j)
#             elif cell == 'k':
#                 key_pos = (i, j)
#             elif cell == 'g':
#                 goal_pos = (i, j)

#     # Generate states EXACTLY like encoder
#     for x in range(size):
#         for y in range(size):
#             cell = grid[x][y]
#             if cell == 'W':
#                 continue  # Skip walls
            
#             # Door cells only have states with has_key=1
#             if (x, y) == door_pos:
#                 for dir in range(4):
#                     states.append((x, y, dir, 1))
#             else:
#                 for has_key in [0, 1]:
#                     for dir in range(4):
#                         states.append((x, y, dir, has_key))

#     state_id = {state:i for i, state in enumerate(states)}

#     # Load policy
#     with open(args.value_policy, 'r') as f:
#         policy = []
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))
#             else:
#                 policy.append(0)  # Handle terminal states

#     # Process each test case
#     actions = []
#     for grid in testcases:
#         x, y, dir, hk = get_agent_state(grid)
        
#         # Validate position
#         if grid[x][y] == 'W':
#             actions.append(0)
#             continue
        
#         current_state = (x, y, dir, hk)
#         state_idx = state_id.get(current_state, -1)
        
#         if state_idx == -1 or state_idx >= len(policy):
#             actions.append(0)
#         else:
#             actions.append(policy[state_idx])

#     print(' '.join(map(str, actions)))

# if __name__ == "__main__":
#     main()












# import argparse

# def parse_testcase_file(filename):
#     testcases = []
#     current_grid = []
#     with open(filename, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if line.startswith("Testcase"):
#                 if current_grid:
#                     testcases.append(current_grid)
#                     current_grid = []
#             elif line:
#                 current_grid.append(line.split())
#     if current_grid:
#         testcases.append(current_grid)
#     return testcases

# def get_agent_state(grid):
#     size = len(grid)
#     x, y, direction = -1, -1, -1
#     key_present = False
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell in ['>', '<', '^', 'v']:
#                 direction = {'^': 0, '>': 1, 'v': 2, '<': 3}[cell]
#                 x, y = i, j
#             if cell == 'k':
#                 key_present = True
#     has_key = not key_present  # Key collected if not present in grid
#     return (x, y, direction, 1 if has_key else 0)

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     testcases = parse_testcase_file(args.gridworld)
#     if not testcases:
#         print("0")
#         return

#     # Build states from MDP structure (same as encoder)
#     size = len(testcases[0])
#     states = []
#     for x in range(size):
#         for y in range(size):
#             for dir in range(4):
#                 for has_key in [0, 1]:
#                     states.append((x, y, dir, has_key))
#     state_id = {state: i for i, state in enumerate(states)}

#     # Load policy
#     with open(args.value_policy, 'r') as f:
#         policy = [int(line.strip().split()[1]) for line in f if line.strip()]

#     actions = []
#     for grid in testcases:
#         x, y, dir, hk = get_agent_state(grid)
#         if (x, y, dir, hk) not in state_id:
#             actions.append(0)
#             continue
#         state_idx = state_id[(x, y, dir, hk)]
#         actions.append(policy[state_idx])

#     print(' '.join(map(str, actions)))

# if __name__ == "__main__":
#     main()
























# import argparse

# def parse_testcase_file(filename):
#     testcases = []
#     current_grid = []
#     with open(filename, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if line.startswith("Testcase"):
#                 if current_grid:
#                     testcases.append(current_grid)
#                     current_grid = []
#             elif line:
#                 current_grid.append(line.split())
#     if current_grid:
#         testcases.append(current_grid)
#     return testcases

# def get_agent_state(grid):
#     size = len(grid)
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell in ['>', '<', '^', 'v']:
#                 direction = {'^': 0, '>': 1, 'v': 2, '<': 3}[cell]
#                 x, y = i, j
#     key_present = any('k' in row for row in grid)
#     has_key = not key_present
#     return (x, y, direction, 1 if has_key else 0)

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     testcases = parse_testcase_file(args.gridworld)
    
#     with open(args.mdp, 'r') as f:
#         mdp_lines = f.readlines()
    
#     size = len(testcases[0]) if testcases else 0
#     door_pos = None
#     key_pos = None
#     states = []

#     for x in range(size):
#         for y in range(size):
#             cell = testcases[0][x][y]
#             if cell == 'd':
#                 door_pos = (x, y)
#             elif cell == 'k':
#                 key_pos = (x, y)

#     for x in range(size):
#         for y in range(size):
#             cell = testcases[0][x][y]
#             if cell == 'W':
#                 continue
#             if cell == 'd':
#                 for dir in range(4):
#                     states.append((x, y, dir, 1))
#             else:
#                 for hk in [0, 1]:
#                     for dir in range(4):
#                         states.append((x, y, dir, hk))

#     state_id = {state: i for i, state in enumerate(states)}
    
#     policy = []
#     with open(args.value_policy, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))

#     actions = []
#     for grid in testcases:
#         x, y, direction, has_key = get_agent_state(grid)
#         current_state = (x, y, direction, has_key)
#         state_idx = state_id.get(current_state, -1)
#         if state_idx == -1:
#             actions.append(0)
#         else:
#             actions.append(policy[state_idx])
    
#     print(' '.join(map(str, actions)))

# if __name__ == "__main__":
#     main()























# import argparse

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     with open(args.gridworld, 'r') as f:
#         grid = [line.strip().split() for line in f]

#     size = len(grid)
#     agent = None
#     key_present = False
#     for i in range(size):
#         for j in range(size):
#             cell = grid[i][j]
#             if cell in ['>', '<', '^', 'v']:
#                 agent = (i, j, {'^':0, '>':1, 'v':2, '<':3}[cell])
#             if cell == 'k':
#                 key_present = True

#     has_key = not key_present

#     door_pos = None
#     key_pos = None
#     for i in range(size):
#         for j in range(size):
#             if grid[i][j] == 'd':
#                 door_pos = (i, j)
#             elif grid[i][j] == 'k':
#                 key_pos = (i, j)

#     if agent[0] == door_pos[0] and agent[1] == door_pos[1]:
#         has_key = True

#     states = []
#     for x in range(size):
#         for y in range(size):
#             cell = grid[x][y]
#             if cell == 'W':
#                 continue
#             if cell == 'd':
#                 for dir in range(4):
#                     states.append((x, y, dir, 1))
#             else:
#                 for hk in [0, 1]:
#                     for dir in range(4):
#                         states.append((x, y, dir, hk))

#     current_state = (agent[0], agent[1], agent[2], 1 if has_key else 0)
#     try:
#         state_id = states.index(current_state)
#     except ValueError:
#         print(0)
#         return

#     with open(args.value_policy, 'r') as f:
#         lines = f.readlines()
#         action = int(lines[state_id].split()[1])

#     print(action)

# if __name__ == "__main__":
#     main()















# import argparse
# import sys

# def parse_mdp(mdp_file):
#     states = []
#     with open(mdp_file, 'r') as f:
#         for line in f:
#             if line.startswith('transition'):
#                 parts = line.strip().split()
#                 s1 = int(parts[1])
#                 s2 = int(parts[3])
#                 states.append((s1, s2))
#     return states

# def parse_policy(policy_file):
#     policy = []
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))
#     return policy

# def get_agent_state(test_grid):
#     dir_map = {'^': 0, '>': 1, 'v': 2, '<': 3}
#     has_key = 'k' not in ''.join(''.join(row) for row in test_grid)
    
#     for y, row in enumerate(test_grid):
#         for x, c in enumerate(row):
#             if c in dir_map:
#                 return (x, y, dir_map[c], has_key)
#     return None

# def generate_states(grid, door_pos):
#     states = []
#     dirs = [0, 1, 2, 3]  # 0:N, 1:E, 2:S, 3:W
#     for y in range(len(grid)):
#         for x in range(len(grid[y])):
#             cell = grid[y][x]
#             if cell == 'W':
#                 continue
#             for dir in dirs:
#                 for has_key in [False, True]:
#                     if cell == 'd' and not has_key:
#                         continue
#                     states.append((x, y, dir, has_key))
#     return states

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     # Parse test gridworld
#     with open(args.gridworld, 'r') as f:
#         test_grid = [list(line.strip()) for line in f if line.strip()]
    
#     # Get current agent state
#     agent_state = get_agent_state(test_grid)
#     if not agent_state:
#         print("0")
#         return
    
#     # Generate all possible states
#     door_pos = None
#     for y, row in enumerate(test_grid):
#         for x, c in enumerate(row):
#             if c == 'd':
#                 door_pos = (x, y)
#     states = generate_states(test_grid, door_pos)
#     state_ids = {state: i for i, state in enumerate(states)}
    
#     # Get policy
#     with open(args.value_policy, 'r') as f:
#         policy = [int(line.strip().split()[1]) for line in f if line.strip()]
    
#     # Find matching state ID
#     current_id = state_ids.get(agent_state, -1)
#     if 0 <= current_id < len(policy):
#         print(policy[current_id])
#     else:
#         print("0")

# if __name__ == "__main__":
#     main()




















# import argparse
# import sys

# def parse_mdp(mdp_file):
#     states = []
#     with open(mdp_file, 'r') as f:
#         for line in f:
#             if line.startswith('transition'):
#                 parts = line.strip().split()
#                 s1 = int(parts[1])
#                 s2 = int(parts[3])
#                 states.append((s1, s2))
#     return states

# def parse_policy(policy_file):
#     policy = []
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))
#     return policy

# def get_agent_state(test_grid):
#     dir_map = {'^': 0, '>': 1, 'v': 2, '<': 3}
#     has_key = 'k' not in ''.join(''.join(row) for row in test_grid)
    
#     for y, row in enumerate(test_grid):
#         for x, c in enumerate(row):
#             if c in dir_map:
#                 return (x, y, dir_map[c], has_key)
#     return None

# def generate_states(grid, door_pos):
#     states = []
#     dirs = [0, 1, 2, 3]  # 0:N, 1:E, 2:S, 3:W
#     for y in range(len(grid)):
#         for x in range(len(grid[y])):
#             cell = grid[y][x]
#             if cell == 'W':
#                 continue
#             for dir in dirs:
#                 for has_key in [False, True]:
#                     if cell == 'd' and not has_key:
#                         continue
#                     states.append((x, y, dir, has_key))
#     return states

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     # Parse test gridworld
#     with open(args.gridworld, 'r') as f:
#         test_grid = [list(line.strip()) for line in f if line.strip()]
    
#     # Get current agent state
#     agent_state = get_agent_state(test_grid)
#     if not agent_state:
#         print("0")
#         return
    
#     # Generate all possible states
#     door_pos = None
#     for y, row in enumerate(test_grid):
#         for x, c in enumerate(row):
#             if c == 'd':
#                 door_pos = (x, y)
#     states = generate_states(test_grid, door_pos)
#     state_ids = {state: i for i, state in enumerate(states)}
    
#     # Get policy
#     with open(args.value_policy, 'r') as f:
#         policy = [int(line.strip().split()[1]) for line in f if line.strip()]
    
#     # Find matching state ID
#     current_id = state_ids.get(agent_state, -1)
#     if 0 <= current_id < len(policy):
#         print(policy[current_id])
#     else:
#         print("0")

# if __name__ == "__main__":
#     main()












# import argparse
# import sys

# def parse_mdp(mdp_file):
#     states = []
#     with open(mdp_file, 'r') as f:
#         for line in f:
#             if line.startswith('transition'):
#                 parts = line.strip().split()
#                 s1 = int(parts[1])
#                 s2 = int(parts[3])
#                 states.append((s1, s2))
#     return states

# def parse_policy(policy_file):
#     policy = []
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy.append(int(parts[1]))
#     return policy

# def get_agent_state(test_grid):
#     dir_map = {'^': 0, '>': 1, 'v': 2, '<': 3}
#     has_key = 'k' not in ''.join(''.join(row) for row in test_grid)
    
#     for y, row in enumerate(test_grid):
#         for x, c in enumerate(row):
#             if c in dir_map:
#                 return (x, y, dir_map[c], has_key)
#     return None

# def generate_states(grid, door_pos):
#     states = []
#     dirs = [0, 1, 2, 3]  # 0:N, 1:E, 2:S, 3:W
#     for y in range(len(grid)):
#         for x in range(len(grid[y])):
#             cell = grid[y][x]
#             if cell == 'W':
#                 continue
#             for dir in dirs:
#                 for has_key in [False, True]:
#                     if cell == 'd' and not has_key:
#                         continue
#                     states.append((x, y, dir, has_key))
#     return states

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--value-policy', required=True)
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     # Parse test gridworld
#     with open(args.gridworld, 'r') as f:
#         test_grid = [list(line.strip()) for line in f if line.strip()]
    
#     # Get current agent state
#     agent_state = get_agent_state(test_grid)
#     if not agent_state:
#         print("0")
#         return
    
#     # Generate all possible states
#     door_pos = None
#     for y, row in enumerate(test_grid):
#         for x, c in enumerate(row):
#             if c == 'd':
#                 door_pos = (x, y)
#     states = generate_states(test_grid, door_pos)
#     state_ids = {state: i for i, state in enumerate(states)}
    
#     # Debug: Print key state info
#     print(f"Agent State: {agent_state}", file=sys.stderr)
#     print(f"Total States: {len(states)}", file=sys.stderr)
#     print(f"State Exists: {agent_state in state_ids}", file=sys.stderr)
    
#     # Get policy with error handling
#     try:
#         with open(args.value_policy, 'r') as f:
#             policy = [int(line.strip().split()[1]) for line in f if line.strip()]
#     except:
#         policy = [0] * len(states)
    
#     # Find matching state ID with bounds check
#     current_id = state_ids.get(agent_state, -1)
#     if 0 <= current_id < len(policy):
#         print(policy[current_id])
#     else:
#         print("0")  # Default action

# if __name__ == "__main__":
#     main()


































import argparse

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--gridworld', required=True)
    args = parser.parse_args()

    grid = []
    with open(args.gridworld, 'r') as f:
        for line in f:
            grid.append(line.strip().split())

    size = len(grid)
    key_pos = None
    door_pos = None
    goal_pos = None
    for i in range(size):
        for j in range(size):
            if grid[i][j] == 'k':
                key_pos = (i, j)
            elif grid[i][j] == 'd':
                door_pos = (i, j)
            elif grid[i][j] == 'g':
                goal_pos = (i, j)

    states = []
    for x in range(size):
        for y in range(size):
            cell = grid[x][y]
            if cell == 'W':
                continue
            if cell == 'd':
                for dir in range(4):
                    states.append((x, y, dir, 1))
            else:
                for has_key in [0, 1]:
                    for dir in range(4):
                        states.append((x, y, dir, has_key))

    state_id = {state: i for i, state in enumerate(states)}
    num_states = len(states)
    num_actions = 4
    end_states = [state_id[state] for state in states if (state[0], state[1]) == goal_pos]

    transitions = []
    dirs = [(-1, 0), (0, 1), (1, 0), (0, -1)]

    for s in states:
        x, y, dir, hk = s
        s_id = state_id[s]
        if (x, y) == goal_pos:
            for a in range(num_actions):
                transitions.append(f"transition {s_id} {a} {s_id} 0.0 1.0")
            continue

        for a in range(num_actions):
            if a == 0:
                max_steps = 0
                cx, cy = x, y
                for step in range(1, 4):
                    nx = cx + dirs[dir][0]
                    ny = cy + dirs[dir][1]
                    if nx < 0 or nx >= size or ny < 0 or ny >= size:
                        break
                    cell = grid[nx][ny]
                    if cell == 'W' or (cell == 'd' and hk == 0):
                        break
                    max_steps += 1
                    cx, cy = nx, ny

                step_probs = {1: 0.5, 2: 0.3, 3: 0.2}
                actual_probs = {}
                for intended, prob in step_probs.items():
                    actual = min(intended, max_steps)
                    actual_probs[actual] = actual_probs.get(actual, 0) + prob

                if max_steps == 0:
                    actual_probs[0] = 1.0

                for actual, prob in actual_probs.items():
                    if actual == 0:
                        nx, ny = x, y
                    else:
                        nx = x + dirs[dir][0] * actual
                        ny = y + dirs[dir][1] * actual
                        if nx < 0 or nx >= size or ny < 0 or ny >= size:
                            nx, ny = x, y
                        else:
                            cell = grid[nx][ny]
                            if cell == 'W' or (cell == 'd' and hk == 0):
                                nx, ny = x, y

                    new_hk = hk
                    if (nx, ny) == key_pos and hk == 0:
                        new_hk = 1

                    new_dir = dir
                    new_state = (nx, ny, new_dir, new_hk)
                    if new_state in state_id:
                        new_s_id = state_id[new_state]
                        reward = -1.0
                        if (nx, ny) == goal_pos:
                            reward = -1.0
                        transitions.append(f"transition {s_id} {a} {new_s_id} {reward} {prob:.6f}")
            else:
                if a == 1:
                    dir_probs = [((dir - 1) % 4, 0.9), ((dir + 2) % 4, 0.1)]
                elif a == 2:
                    dir_probs = [((dir + 1) % 4, 0.9), ((dir + 2) % 4, 0.1)]
                else:
                    dir_probs = [((dir + 2) % 4, 0.8), ((dir - 1) % 4, 0.1), ((dir + 1) % 4, 0.1)]

                for new_dir, prob in dir_probs:
                    new_hk = hk
                    if (x, y) == key_pos and hk == 0:
                        new_hk = 1
                    new_state = (x, y, new_dir, new_hk)
                    if new_state in state_id:
                        new_s_id = state_id[new_state]
                        transitions.append(f"transition {s_id} {a} {new_s_id} -1.0 {prob:.6f}")

    print(f"numStates {num_states}")
    print(f"numActions {num_actions}")
    print(f"end {' '.join(map(str, end_states))}")
    for trans in transitions:
        print(trans)
    print("mdptype episodic")
    print("discount 1.0")

if __name__ == "__main__":
    main()














# import argparse

# def parse_gridworld(file_path):
#     grid = []
#     start = None
#     goal = None
#     key = None
#     door = None
#     with open(file_path, 'r') as f:
#         for y, line in enumerate(f):
#             line = line.strip()
#             if not line:
#                 continue
#             row = list(line)
#             grid.append(row)
#             for x, c in enumerate(row):
#                 if c == 's':
#                     start = (x, y)
#                 elif c == 'g':
#                     goal = (x, y)
#                 elif c == 'k':
#                     key = (x, y)
#                 elif c == 'd':
#                     door = (x, y)
#     return grid, start, goal, key, door

# def generate_states(grid, door_pos):
#     states = []
#     dirs = [0, 1, 2, 3]  # 0:N, 1:E, 2:S, 3:W
#     for y in range(len(grid)):
#         for x in range(len(grid[y])):
#             cell = grid[y][x]
#             if cell == 'W':
#                 continue
#             for dir in dirs:
#                 for has_key in [False, True]:
#                     if cell == 'd' and not has_key:
#                         continue
#                     states.append((x, y, dir, has_key))
#     return states

# def get_move_direction(dir):
#     return [(0, -1), (1, 0), (0, 1), (-1, 0)][dir]

# def calculate_slide(grid, x, y, dir, has_key, door_pos):
#     dx, dy = get_move_direction(dir)
#     max_slide = 0
#     for steps in range(1, 4):
#         nx = x + dx * steps
#         ny = y + dy * steps
#         if nx < 0 or ny < 0 or ny >= len(grid) or nx >= len(grid[ny]):
#             break
#         if grid[ny][nx] == 'W':
#             break
#         if grid[ny][nx] == 'd' and not has_key:
#             break
#         max_slide = steps
#     return max_slide

# def generate_transitions(grid, states, key_pos, door_pos, goal_pos):
#     transitions = []
#     state_ids = {state: i for i, state in enumerate(states)}
    
#     for state_id, (x, y, dir, has_key) in enumerate(states):
#         if (x, y) == goal_pos:
#             continue
            
#         # Move forward (action 0)
#         if (x, y) != goal_pos:
#             dx, dy = get_move_direction(dir)
#             max_slide = calculate_slide(grid, x, y, dir, has_key, door_pos)
#             probs = {1: 0.5, 2: 0.3, 3: 0.2}
#             adjusted_probs = {}
            
#             total = 0.0
#             for slide in range(1, 4):
#                 if slide > max_slide:
#                     prob = probs.get(slide, 0)
#                     adjusted_probs[max_slide] = adjusted_probs.get(max_slide, 0) + prob
#                 else:
#                     adjusted_probs[slide] = probs.get(slide, 0)
            
#             if max_slide == 0:
#                 adjusted_probs[0] = 1.0
#             else:
#                 total = sum(adjusted_probs.values())
#                 if total < 1.0:
#                     adjusted_probs[max_slide] += 1.0 - total
            
#             for slide, prob in adjusted_probs.items():
#                 if prob <= 0:
#                     continue
                    
#                 nx = x + dx * slide
#                 ny = y + dy * slide
#                 new_has_key = has_key
                
#                 # Check key pickup during sliding
#                 if not has_key and key_pos:
#                     for step in range(1, slide + 1):
#                         sx = x + dx * step
#                         sy = y + dy * step
#                         if (sx, sy) == key_pos:
#                             new_has_key = True
#                             break  # Key acquired during slide
                
#                 # Block door transitions without key
#                 if grid[ny][nx] == 'd' and not new_has_key:
#                     continue
                
#                 next_state = (nx, ny, dir, new_has_key)
#                 if next_state in state_ids:
#                     reward = 0 if (nx, ny) == goal_pos else -1
#                     transitions.append(
#                         (state_id, 0, state_ids[next_state], reward, prob)
#                     )

#         # Turn actions
#         turn_probs = {
#             1: [((dir - 1) % 4, 0.9), ((dir + 2) % 4, 0.1)],  # Left
#             2: [((dir + 1) % 4, 0.9), ((dir + 2) % 4, 0.1)],  # Right
#             3: [((dir + 2) % 4, 0.8), ((dir - 1) % 4, 0.1), ((dir + 1) % 4, 0.1)]  # Around
#         }
        
#         for action in [1, 2, 3]:
#             for new_dir, prob in turn_probs[action]:
#                 next_state = (x, y, new_dir, has_key)
#                 if next_state in state_ids:
#                     transitions.append(
#                         (state_id, action, state_ids[next_state], -1, prob)
#                     )
    
#     end_states = [state_ids[(goal_pos[0], goal_pos[1], d, hk)] 
#                  for d in [0,1,2,3] for hk in [False,True] 
#                  if (goal_pos[0], goal_pos[1], d, hk) in state_ids]
    
#     return transitions, end_states

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()
    
#     grid, start, goal, key_pos, door_pos = parse_gridworld(args.gridworld)
#     states = generate_states(grid, door_pos)
#     transitions, end_states = generate_transitions(grid, states, key_pos, door_pos, goal)
    
#     print(f"numStates {len(states)}")
#     print(f"numActions 4")
#     print(f"end {' '.join(map(str, end_states))}")
#     for t in transitions:
#         print(f"transition {t[0]} {t[1]} {t[2]} {t[3]} {t[4]:.6f}")
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     main()






























# import argparse
# import sys

# def parse_gridworld(file_path):
#     grid = []
#     start = None
#     goal = None
#     key = None
#     door = None
#     with open(file_path, 'r') as f:
#         for y, line in enumerate(f):
#             line = line.strip()
#             if not line:
#                 continue
#             row = list(line)
#             grid.append(row)
#             for x, c in enumerate(row):
#                 if c == 's':
#                     start = (x, y)
#                 elif c == 'g':
#                     goal = (x, y)
#                 elif c == 'k':
#                     key = (x, y)
#                 elif c == 'd':
#                     door = (x, y)
#     return grid, start, goal, key, door

# def generate_states(grid, door_pos):
#     states = []
#     dirs = [0, 1, 2, 3]  # 0:N, 1:E, 2:S, 3:W
#     for y in range(len(grid)):
#         for x in range(len(grid[y])):
#             cell = grid[y][x]
#             if cell == 'W':
#                 continue
#             for dir in dirs:
#                 for has_key in [False, True]:
#                     if cell == 'd' and not has_key:
#                         continue
#                     states.append((x, y, dir, has_key))
#     return states

# def get_move_direction(dir):
#     return [(0, -1), (1, 0), (0, 1), (-1, 0)][dir]

# def calculate_slide(grid, x, y, dir, has_key, door_pos):
#     dx, dy = get_move_direction(dir)
#     max_slide = 0
#     for steps in range(1, 4):
#         nx = x + dx * steps
#         ny = y + dy * steps
#         if nx < 0 or ny < 0 or ny >= len(grid) or nx >= len(grid[ny]):
#             break
#         if grid[ny][nx] == 'W':
#             break
#         if grid[ny][nx] == 'd' and not has_key:
#             break
#         max_slide = steps
#     return max_slide

# def generate_transitions(grid, states, key_pos, door_pos, goal_pos):
#     transitions = []
#     state_ids = {state: i for i, state in enumerate(states)}
    
#     for state_id, (x, y, dir, has_key) in enumerate(states):
#         if (x, y) == goal_pos:
#             continue
            
#         # Move forward (action 0)
#         if (x, y) != goal_pos:
#             dx, dy = get_move_direction(dir)
#             max_slide = calculate_slide(grid, x, y, dir, has_key, door_pos)
#             probs = {1: 0.5, 2: 0.3, 3: 0.2}
#             adjusted_probs = {}
            
#             total = 0.0
#             for slide in range(1, 4):
#                 if slide > max_slide:
#                     prob = probs.get(slide, 0)
#                     adjusted_probs[max_slide] = adjusted_probs.get(max_slide, 0) + prob
#                 else:
#                     adjusted_probs[slide] = probs.get(slide, 0)
            
#             if max_slide == 0:
#                 adjusted_probs[0] = 1.0
#             else:
#                 total = sum(adjusted_probs.values())
#                 if total < 1.0:
#                     adjusted_probs[max_slide] += 1.0 - total
            
#             for slide, prob in adjusted_probs.items():
#                 if prob <= 0:
#                     continue
                    
#                 nx = x + dx * slide
#                 ny = y + dy * slide
#                 new_has_key = has_key
                
#                 # Check key pickup during sliding
#                 if not has_key and key_pos:
#                     for step in range(1, slide+1):
#                         sx = x + dx * step
#                         sy = y + dy * step
#                         if (sx, sy) == key_pos:
#                             new_has_key = True
#                             break
                
#                 # Handle door transitions
#                 if grid[ny][nx] == 'd' and not new_has_key:
#                     continue  # Block door if no key
                
#                 next_state = (nx, ny, dir, new_has_key)
#                 if next_state in state_ids:
#                     reward = 0 if (nx, ny) == goal_pos else -1
#                     transitions.append(
#                         (state_id, 0, state_ids[next_state], reward, prob)
        
#         # Turn actions
#         turn_probs = {
#             1: [((dir - 1) % 4, 0.9), ((dir + 2) % 4, 0.1)],  # Left
#             2: [((dir + 1) % 4, 0.9), ((dir + 2) % 4, 0.1)],  # Right
#             3: [((dir + 2) % 4, 0.8), ((dir - 1) % 4, 0.1), ((dir + 1) % 4, 0.1)]  # Around
#         }
        
#         for action in [1, 2, 3]:
#             for new_dir, prob in turn_probs[action]:
#                 next_state = (x, y, new_dir, has_key)
#                 if next_state in state_ids:
#                     transitions.append(
#                         (state_id, action, state_ids[next_state], -1, prob))
    
#     end_states = [state_ids[(goal_pos[0], goal_pos[1], d, hk)] 
#                  for d in [0,1,2,3] for hk in [False,True] 
#                  if (goal_pos[0], goal_pos[1], d, hk) in state_ids]
    
#     return transitions, end_states

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()
    
#     grid, start, goal, key_pos, door_pos = parse_gridworld(args.gridworld)
#     states = generate_states(grid, door_pos)
#     transitions, end_states = generate_transitions(grid, states, key_pos, door_pos, goal)
    
#     print(f"numStates {len(states)}")
#     print(f"numActions 4")
#     print(f"end {' '.join(map(str, end_states))}")
#     for t in transitions:
#         print(f"transition {t[0]} {t[1]} {t[2]} {t[3]} {t[4]:.6f}")
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     main()


# import argparse

# def parse_gridworld(file_path):
#     grid = []
#     start = None
#     goal = None
#     key = None
#     door = None
#     with open(file_path, 'r') as f:
#         for y, line in enumerate(f):
#             line = line.strip()
#             if not line:
#                 continue
#             row = list(line)
#             grid.append(row)
#             for x, c in enumerate(row):
#                 if c == 's':
#                     start = (x, y)
#                 elif c == 'g':
#                     goal = (x, y)
#                 elif c == 'k':
#                     key = (x, y)
#                 elif c == 'd':
#                     door = (x, y)
#     return grid, start, goal, key, door

# def generate_states(grid, door_pos):
#     states = []
#     dirs = [0, 1, 2, 3]  # 0:N, 1:E, 2:S, 3:W
#     for y in range(len(grid)):
#         for x in range(len(grid[y])):
#             cell = grid[y][x]
#             if cell == 'W':
#                 continue
#             for dir in dirs:
#                 for has_key in [False, True]:
#                     if cell == 'd' and not has_key:
#                         continue
#                     states.append((x, y, dir, has_key))
#     return states

# def get_move_direction(dir):
#     return [(0, -1), (1, 0), (0, 1), (-1, 0)][dir]

# def calculate_slide(grid, x, y, dir, has_key, door_pos):
#     dx, dy = get_move_direction(dir)
#     max_slide = 0
#     for steps in range(1, 4):
#         nx = x + dx * steps
#         ny = y + dy * steps
#         if nx < 0 or ny < 0 or ny >= len(grid) or nx >= len(grid[ny]):
#             break
#         if grid[ny][nx] == 'W':
#             break
#         if grid[ny][nx] == 'd' and not has_key:
#             break
#         max_slide = steps
#     return max_slide

# def generate_transitions(grid, states, key_pos, door_pos, goal_pos):
#     transitions = []
#     state_ids = {state: i for i, state in enumerate(states)}
    
#     for state_id, (x, y, dir, has_key) in enumerate(states):
#         if (x, y) == goal_pos:
#             continue
            
#         # Move forward (action 0)
#         if (x, y) != goal_pos:
#             dx, dy = get_move_direction(dir)
#             max_slide = calculate_slide(grid, x, y, dir, has_key, door_pos)
#             probs = {1: 0.5, 2: 0.3, 3: 0.2}
#             adjusted_probs = {}
            
#             total = 0.0
#             for slide in range(1, 4):
#                 if slide > max_slide:
#                     prob = probs.get(slide, 0)
#                     adjusted_probs[max_slide] = adjusted_probs.get(max_slide, 0) + prob
#                 else:
#                     adjusted_probs[slide] = probs.get(slide, 0)
            
#             if max_slide == 0:
#                 adjusted_probs[0] = 1.0
#             else:
#                 total = sum(adjusted_probs.values())
#                 if total < 1.0:
#                     adjusted_probs[max_slide] += 1.0 - total
            
#             for slide, prob in adjusted_probs.items():
#                 if prob <= 0:
#                     continue
                    
#                 nx = x + dx * slide
#                 ny = y + dy * slide
#                 new_has_key = has_key
                
#                 if not has_key:
#                     key_acquired = False
#                     for step in range(1, slide + 1):
#                         sx = x + dx * step
#                         sy = y + dy * step
#                         if (sx, sy) == key_pos:
#                             key_acquired = True
#                     new_has_key = has_key or key_acquired
                
#                 if (nx, ny) == goal_pos:
#                     reward = 0
#                 else:
#                     reward = -1
                
#                 next_state = (nx, ny, dir, new_has_key)
#                 if next_state in state_ids:
#                     transitions.append(  # FIXED HERE
#                         (state_id, 0, state_ids[next_state], reward, prob)
#                     )  # Added closing parenthesis

#         # Turn actions
#         turn_probs = {
#             1: [((dir - 1) % 4, 0.9), ((dir + 2) % 4, 0.1)],  # Left
#             2: [((dir + 1) % 4, 0.9), ((dir + 2) % 4, 0.1)],  # Right
#             3: [((dir + 2) % 4, 0.8), ((dir - 1) % 4, 0.1), ((dir + 1) % 4, 0.1)]  # Around
#         }
        
#         for action in [1, 2, 3]:
#             for new_dir, prob in turn_probs[action]:
#                 next_state = (x, y, new_dir, has_key)
#                 if next_state in state_ids:
#                     transitions.append(
#                         (state_id, action, state_ids[next_state], -1, prob)
#                     )
    
#     end_states = [state_ids[(goal_pos[0], goal_pos[1], d, hk)] 
#                  for d in [0,1,2,3] for hk in [False,True] 
#                  if (goal_pos[0], goal_pos[1], d, hk) in state_ids]
    
#     return transitions, end_states

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()
    
#     grid, start, goal, key_pos, door_pos = parse_gridworld(args.gridworld)
#     states = generate_states(grid, door_pos)
#     transitions, end_states = generate_transitions(grid, states, key_pos, door_pos, goal)
    
#     print(f"numStates {len(states)}")
#     print(f"numActions 4")
#     print(f"end {' '.join(map(str, end_states))}")
#     for t in transitions:
#         print(f"transition {t[0]} {t[1]} {t[2]} {t[3]} {t[4]:.6f}")
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     main()



































































































import argparse
import numpy as np
from pulp import *

def parse_mdp(file_path):
    transitions = {}
    end_states = set()
    gamma = 0.0
    mdptype = ''
    num_states = 0
    num_actions = 0

    with open(file_path, 'r') as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            parts = line.split()
            if parts[0] == 'numStates':
                num_states = int(parts[1])
            elif parts[0] == 'numActions':
                num_actions = int(parts[1])
                transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
            elif parts[0] == 'end':
                end_states = set(map(int, parts[1:]))
            elif parts[0] == 'transition':
                s1 = int(parts[1])
                ac = int(parts[2])
                s2 = int(parts[3])
                r = float(parts[4])
                p = float(parts[5])
                transitions[s1][ac].append((s2, r, p))
            elif parts[0] == 'mdptype':
                mdptype = parts[1]
            elif parts[0] == 'discount':
                gamma = float(parts[1])
    return transitions, num_states, num_actions, end_states, mdptype, gamma

def evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma):
    non_terminal = [s for s in range(num_states) if s not in end_states]
    if not non_terminal:
        return {s: 0.0 for s in range(num_states)}
    
    n = len(non_terminal)
    A = np.zeros((n, n))
    B = np.zeros(n)
    s_to_idx = {s: i for i, s in enumerate(non_terminal)}

    for i, s in enumerate(non_terminal):
        a = policy[s]
        A[i][i] = 1.0
        rhs = 0.0
        for (s_next, r, p_trans) in transitions[s][a]:
            rhs += p_trans * r
            if s_next in end_states:
                continue
            if s_next in s_to_idx:
                j = s_to_idx[s_next]
                A[i][j] -= gamma * p_trans
        B[i] = rhs

    try:
        solution = np.linalg.solve(A, B)
    except np.linalg.LinAlgError:
        solution = np.zeros(n)
    
    V = {s: 0.0 for s in end_states}
    for i, s in enumerate(non_terminal):
        V[s] = solution[i]
    return V

def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
    policy = [0] * num_states
    while True:
        V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
        new_policy = policy.copy()
        policy_changed = False
        for s in range(num_states):
            if s in end_states:
                continue
            max_q = -float('inf')
            best_a = 0
            for a in range(num_actions):
                q = 0.0
                for (s_next, r, p) in transitions[s][a]:
                    if s_next in end_states:
                        q += p * r
                    else:
                        q += p * (r + gamma * V[s_next])
                if q > max_q or (q == max_q and a < best_a):
                    max_q = q
                    best_a = a
            if new_policy[s] != best_a:
                policy_changed = True
                new_policy[s] = best_a
        if not policy_changed:
            break
        policy = new_policy
    for s in end_states:
        policy[s] = 0
    return V, policy

def linear_programming(transitions, num_states, num_actions, end_states, gamma):
    prob = LpProblem("MDP_LP", LpMinimize)
    V_vars = {}
    for s in range(num_states):
        if s in end_states:
            V_vars[s] = 0.0
        else:
            V_vars[s] = LpVariable(f"V_{s}", cat='Continuous')

    prob += lpSum([V_vars[s] for s in range(num_states) if s not in end_states])

    for s in range(num_states):
        if s in end_states:
            continue
        for a in range(num_actions):
            sum_expr = 0
            for (s_next, r, p) in transitions[s][a]:
                if s_next in end_states:
                    sum_expr += p * r
                else:
                    sum_expr += p * (r + gamma * V_vars[s_next])
            prob += (V_vars[s] >= sum_expr)

    prob.solve(PULP_CBC_CMD(msg=False))

    V_values = {}
    for s in range(num_states):
        if s in end_states:
            V_values[s] = 0.0
        else:
            V_values[s] = value(V_vars[s])

    policy = [0] * num_states
    for s in range(num_states):
        if s in end_states:
            policy[s] = 0
            continue
        max_q = -float('inf')
        best_a = 0
        for a in range(num_actions):
            q = 0.0
            for (s_next, r, p) in transitions[s][a]:
                if s_next in end_states:
                    q += p * r
                else:
                    q += p * (r + gamma * V_values[s_next])
            if q > max_q or (q == max_q and a < best_a):
                max_q = q
                best_a = a
        policy[s] = best_a
    return V_values, policy

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--mdp', required=True)
    parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
    parser.add_argument('--policy', default=None)
    args = parser.parse_args()

    transitions, num_states, num_actions, end_states, mdptype, gamma = parse_mdp(args.mdp)

    if args.policy:
        with open(args.policy, 'r') as f:
            policy = list(map(int, f.read().split()))
        V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
        optimal_policy = policy
    else:
        if args.algorithm == 'hpi':
            V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
        else:
            V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

    for s in range(num_states):
        if s in end_states:
            print(f"{0.0:.6f} 0")
        else:
            print(f"{V[s]:.6f} {optimal_policy[s]}")

if __name__ == "__main__":
    main()

















































    # import argparse
# import sys
# from collections import defaultdict

# def parse_gridworld(grid_file):
#     grid = []
#     start = None
#     goal = None
#     key = None
#     door = None
#     with open(grid_file, 'r') as f:
#         for r, line in enumerate(f):
#             row = list(line.strip())
#             grid.append(row)
#             for c, cell in enumerate(row):
#                 if cell == 's':
#                     start = (r, c)
#                 elif cell == 'g':
#                     goal = (r, c)
#                 elif cell == 'k':
#                     key = (r, c)
#                 elif cell == 'd':
#                     door = (r, c)
#     return grid, start, goal, key, door

# def state_id(r, c, has_key, direction):
#     return (r * 10 + c) * 2 + has_key * 4 + direction

# def encode_mdp(grid, start, goal, key, door):
#     num_states = len(grid) * len(grid[0]) * 2 * 4  # (x, y, has_key, direction)
#     num_actions = 4  # 0: Forward, 1: Left, 2: Right, 3: Turn around
#     end_states = [state_id(goal[0], goal[1], 1, d) for d in range(4)]
#     transitions = []
    
#     for r in range(len(grid)):
#         for c in range(len(grid[0])):
#             if grid[r][c] == 'W':
#                 continue
#             for has_key in [0, 1]:
#                 for direction in range(4):
#                     s1 = state_id(r, c, has_key, direction)
#                     if (r, c) == goal:
#                         continue
#                     for action in range(num_actions):
#                         transitions.extend(handle_transitions(grid, r, c, has_key, direction, action, key, door))
    
#     mdp_str = f"numStates {num_states}\nnumActions {num_actions}\nend {' '.join(map(str, end_states))}\n"
#     for tr in transitions:
#         mdp_str += f"transition {tr[0]} {tr[1]} {tr[2]} {tr[3]} {tr[4]}\n"
#     mdp_str += "mdptype episodic\ndiscount 0.99\n"
#     return mdp_str

# def handle_transitions(grid, r, c, has_key, direction, action, key, door):
#     transitions = []
#     directions = [(0, 1), (0, -1), (-1, 0), (1, 0)]  # Right, Left, Up, Down
    
#     if action == 0:  # Move forward (stochastic movement)
#         for steps, prob in [(1, 0.5), (2, 0.3), (3, 0.2)]:
#             temp_r, temp_c = r, c
#             for _ in range(steps):
#                 next_r, next_c = temp_r + directions[direction][0], temp_c + directions[direction][1]
#                 if not (0 <= next_r < len(grid) and 0 <= next_c < len(grid[0])) or grid[next_r][next_c] == 'W':
#                     break
#                 if (next_r, next_c) == door and not has_key:
#                     break  # Block movement if door is locked
#                 temp_r, temp_c = next_r, next_c
#             new_has_key = 1 if (temp_r, temp_c) == key else has_key
#             transitions.append((state_id(r, c, has_key, direction), action, state_id(temp_r, temp_c, new_has_key, direction), -1, prob))
    
#     elif action == 1:  # Turn left
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction - 1) % 4), -1, 0.9))
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction + 2) % 4), -1, 0.1))
    
#     elif action == 2:  # Turn right
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction + 1) % 4), -1, 0.9))
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction + 2) % 4), -1, 0.1))
    
#     elif action == 3:  # Turn around
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction + 2) % 4), -1, 0.8))
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction - 1) % 4), -1, 0.1))
#         transitions.append((state_id(r, c, has_key, direction), action, state_id(r, c, has_key, (direction + 1) % 4), -1, 0.1))
    
#     return transitions

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--gridworld", required=True, help="Path to gridworld file")
#     args = parser.parse_args()
#     grid, start, goal, key, door = parse_gridworld(args.gridworld)
#     mdp_output = encode_mdp(grid, start, goal, key, door)
#     sys.stdout.write(mdp_output)













































# import argparse
# import sys
# from collections import defaultdict

# def parse_gridworld(grid_file):
#     grid = []
#     start = None
#     goal = None
#     key = None
#     door = None
#     with open(grid_file, 'r') as f:
#         for r, line in enumerate(f):
#             row = list(line.strip())
#             grid.append(row)
#             for c, cell in enumerate(row):
#                 if cell == 's':
#                     start = (r, c)
#                 elif cell == 'g':
#                     goal = (r, c)
#                 elif cell == 'k':
#                     key = (r, c)
#                 elif cell == 'd':
#                     door = (r, c)
#     return grid, start, goal, key, door

# def state_id(r, c, has_key, direction, grid):
#     return ((r * len(grid[0]) + c) * 2 + has_key) * 4 + direction

# def encode_mdp(grid, start, goal, key, door):
#     num_states = len(grid) * len(grid[0]) * 2 * 4  # (x, y, has_key, direction)
#     num_actions = 4  # 0: Forward, 1: Left, 2: Right, 3: Turn around
#     end_states = [state_id(goal[0], goal[1], 1, d, grid) for d in range(4)]
#     transitions = []
    
#     for r in range(len(grid)):
#         for c in range(len(grid[0])):
#             if grid[r][c] == 'W':
#                 continue
#             for has_key in [0, 1]:
#                 for direction in range(4):
#                     s1 = state_id(r, c, has_key, direction, grid)
#                     if (r, c) == goal:
#                         continue
#                     for action in range(num_actions):
#                         transitions.extend(handle_transitions(grid, r, c, has_key, direction, action, state_id))
    
#     mdp_str = f"numStates {num_states}\nnumActions {num_actions}\nend {' '.join(map(str, end_states))}\n"
#     for tr in transitions:
#         mdp_str += f"transition {tr[0]} {tr[1]} {tr[2]} {tr[3]} {tr[4]}\n"
#     mdp_str += "mdptype episodic\ndiscount 0.99\n"
#     return mdp_str

# def handle_transitions(grid, r, c, has_key, direction, action, state_id):
#     transitions = []
#     # Handle movement probabilities and turning probabilities here
#     return transitions  # Fill this in with movement logic

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--gridworld", required=True, help="Path to gridworld file")
#     args = parser.parse_args()
#     grid, start, goal, key, door = parse_gridworld(args.gridworld)
#     mdp_output = encode_mdp(grid, start, goal, key, door)
#     sys.stdout.write(mdp_output)




























# import argparse
# import sys
# from collections import defaultdict

# def parse_gridworld(grid_file):
#     grid = []
#     start = None
#     goal = None
#     key = None
#     door = None
#     with open(grid_file, 'r') as f:
#         for r, line in enumerate(f):
#             row = list(line.strip())
#             grid.append(row)
#             for c, cell in enumerate(row):
#                 if cell == 's':
#                     start = (r, c)
#                 elif cell == 'g':
#                     goal = (r, c)
#                 elif cell == 'k':
#                     key = (r, c)
#                 elif cell == 'd':
#                     door = (r, c)
#     return grid, start, goal, key, door

# def encode_mdp(grid, start, goal, key, door):
#     num_states = len(grid) * len(grid[0]) * 2 * 4  # (x, y, has_key, direction)
#     num_actions = 4  # 0: Forward, 1: Left, 2: Right, 3: Turn around
#     end_states = [state_id(goal[0], goal[1], 1, d, grid) for d in range(4)]
#     transitions = []

#     def state_id(r, c, has_key, direction, grid):
#         return ((r * len(grid[0]) + c) * 2 + has_key) * 4 + direction
    
#     for r in range(len(grid)):
#         for c in range(len(grid[0])):
#             if grid[r][c] == 'W':
#                 continue
#             for has_key in [0, 1]:
#                 for direction in range(4):
#                     s1 = state_id(r, c, has_key, direction, grid)
#                     if (r, c) == goal:
#                         continue
#                     for action in range(num_actions):
#                         transitions.extend(handle_transitions(grid, r, c, has_key, direction, action, state_id))
    
#     mdp_str = f"numStates {num_states}\nnumActions {num_actions}\nend {' '.join(map(str, end_states))}\n"
#     for tr in transitions:
#         mdp_str += f"transition {tr[0]} {tr[1]} {tr[2]} {tr[3]} {tr[4]}\n"
#     mdp_str += "mdptype episodic\ndiscount 0.99\n"
#     return mdp_str

# def handle_transitions(grid, r, c, has_key, direction, action, state_id):
#     transitions = []
#     # Handle movement probabilities and turning probabilities here
#     return transitions  # Fill this in with movement logic

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--gridworld", required=True, help="Path to gridworld file")
#     args = parser.parse_args()
#     grid, start, goal, key, door = parse_gridworld(args.gridworld)
#     mdp_output = encode_mdp(grid, start, goal, key, door)
#     sys.stdout.write(mdp_output)
























#
# 
# 
# 
# 
# 














































#  import argparse

# def parse_grid(grid_file):
#     grid = []
#     with open(grid_file, 'r') as f:
#         for line in f:
#             grid.append(line.strip().split())
#     return grid

# def identify_special_cells(grid):
#     walls = set()
#     door = None
#     key = None
#     goal = None
#     for x in range(len(grid)):
#         for y in range(len(grid[0])):
#             cell = grid[x][y]
#             if cell == 'W':
#                 walls.add((x, y))
#             elif cell == 'd':
#                 door = (x, y)
#             elif cell == 'k':
#                 key = (x, y)
#             elif cell == 'g':
#                 goal = (x, y)
#     return walls, door, key, goal

# def generate_states(grid, walls, door):
#     states = []
#     for x in range(len(grid)):
#         for y in range(len(grid[0])):
#             if (x, y) in walls:
#                 continue
#             if (x, y) == door:
#                 # Door requires key (has_key=1)
#                 for dir in range(4):
#                     states.append((x, y, dir, 1))
#             else:
#                 for has_key in [0, 1]:
#                     for dir in range(4):
#                         states.append((x, y, dir, has_key))
#     return states

# def calculate_transitions(grid, states, key_pos, goal_pos):
#     dirs = [(-1,0), (0,1), (1,0), (0,-1)]  # N, E, S, W
#     transitions = []
#     state_id = {s: i for i, s in enumerate(states)}

#     for idx, (x, y, dir, has_key) in enumerate(states):
#         if (x, y) == goal_pos:
#             # Terminal state: self-loop
#             for a in range(4):
#                 transitions.append(f"transition {idx} {a} {idx} 0.0 1.0")
#             continue

#         for action in range(4):
#             if action == 0:  # Move forward
#                 max_slide = 0
#                 cx, cy = x, y
#                 for step in range(1, 4):
#                     nx = cx + dirs[dir][0]
#                     ny = cy + dirs[dir][1]
#                     if nx < 0 or nx >= len(grid) or ny < 0 or ny >= len(grid[0]):
#                         break
#                     if grid[nx][ny] == 'W' or (grid[nx][ny] == 'd' and not has_key):
#                         break
#                     max_slide = step
#                     cx, cy = nx, ny

#                 # Calculate probabilities
#                 probs = {1: 0.5, 2: 0.3, 3: 0.2}
#                 actual_probs = {}
#                 for intended, p in probs.items():
#                     actual = min(intended, max_slide)
#                     actual_probs[actual] = actual_probs.get(actual, 0) + p
#                 if max_slide == 0:
#                     actual_probs[0] = 1.0

#                 # Add transitions
#                 for actual, prob in actual_probs.items():
#                     nx = x + dirs[dir][0] * actual
#                     ny = y + dirs[dir][1] * actual
#                     new_has_key = has_key
#                     if (nx, ny) == key_pos and not has_key:
#                         new_has_key = 1
#                     new_state = (nx, ny, dir, new_has_key)
#                     if new_state in state_id:
#                         transitions.append(
#                             f"transition {idx} {action} {state_id[new_state]} -1.0 {prob:.6f}"
#                         )
#             else:  # Turn actions
#                 if action == 1:  # Turn left
#                     dir_probs = [(dir - 1) % 4, 0.9, (dir + 2) % 4, 0.1]
#                 elif action == 2:  # Turn right
#                     dir_probs = [(dir + 1) % 4, 0.9, (dir + 2) % 4, 0.1]
#                 else:  # Turn around
#                     dir_probs = [(dir + 2) % 4, 0.8, (dir - 1) % 4, 0.1, (dir + 1) % 4, 0.1]

#                 for i in range(0, len(dir_probs), 2):
#                     new_dir, prob = dir_probs[i], dir_probs[i+1]
#                     new_state = (x, y, new_dir, has_key)
#                     if new_state in state_id:
#                         transitions.append(
#                             f"transition {idx} {action} {state_id[new_state]} -1.0 {prob:.6f}"
#                         )
#     return transitions

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--gridworld', required=True)
#     args = parser.parse_args()

#     grid = parse_grid(args.gridworld)
#     walls, door, key, goal = identify_special_cells(grid)
#     states = generate_states(grid, walls, door)
#     transitions = calculate_transitions(grid, states, key, goal)
#     end_states = [i for i, s in enumerate(states) if (s[0], s[1]) == goal]

#     print(f"numStates {len(states)}")
#     print(f"numActions 4")
#     print(f"end {' '.join(map(str, end_states)) if end_states else 'end -1'}")
#     for trans in transitions:
#         print(trans)
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     main()






















# import argparse
# import numpy as np
# from pulp import *

# def parse_mdp(file_path):
#     """Reads an MDP file and extracts the states, actions, transitions, and other parameters."""
#     transitions = {}
#     end_states = set()
#     gamma = 0.0
#     num_states = 0
#     num_actions = 0

#     with open(file_path, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if not line:
#                 continue
#             parts = line.split()
#             if parts[0] == 'numStates':
#                 num_states = int(parts[1])
#             elif parts[0] == 'numActions':
#                 num_actions = int(parts[1])
#                 transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
#             elif parts[0] == 'end' and len(parts) > 1:
#                 end_states = set(map(int, parts[1:]))
#             elif parts[0] == 'transition':
#                 s1, ac, s2 = map(int, parts[1:4])
#                 r, p = float(parts[4]), float(parts[5])
#                 transitions[s1][ac].append((s2, r, p))
#             elif parts[0] == 'mdptype':
#                 mdptype = parts[1]
#             elif parts[0] == 'discount':
#                 gamma = float(parts[1])

#     return transitions, num_states, num_actions, end_states, gamma

# def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Howard's Policy Iteration."""
#     policy = [0] * num_states
#     V = np.zeros(num_states, dtype=np.float64)

#     while True:
#         V_prev = np.copy(V)
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             a = policy[s]
#             V[s] = sum(p * (r + gamma * V_prev[s_next]) for s_next, r, p in transitions[s][a])
#         if np.max(np.abs(V - V_prev)) < 1e-10:
#             break

#         new_policy = policy.copy()
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             max_q, best_a = -float('inf'), 0
#             for a in range(num_actions):
#                 q = sum(p * (r + gamma * V[s_next]) for s_next, r, p in transitions[s][a])
#                 if q > max_q:
#                     max_q, best_a = q, a
#             new_policy[s] = best_a

#         if policy == new_policy:
#             break
#         policy = new_policy

#     return {s: V[s] for s in range(num_states)}, policy  # 🔥 Fixed: Convert V to dictionary

# def linear_programming(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Linear Programming."""
#     prob = LpProblem("MDP_LP", LpMinimize)
#     V_vars = {s: LpVariable(f"V_{s}", cat='Continuous') for s in range(num_states)}

#     # Ensure terminal states have value V(s) = 0
#     for s in end_states:
#         prob += V_vars[s] == 0

#     # Add Bellman constraints for non-terminal states
#     for s in range(num_states):
#         if s in end_states:
#             continue
#         for a in range(num_actions):
#             prob += (V_vars[s] >= sum(p * (r + gamma * V_vars[s_next])
#                                        for s_next, r, p in transitions[s][a]))

#     prob.solve(PULP_CBC_CMD(msg=False))  # Disable solver messages

#     if prob.status != 1:
#         return {s: 0.0 for s in range(num_states)}, [0] * num_states

#     V_values = {s: value(V_vars[s]) for s in range(num_states)}
#     policy = [0] * num_states

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         max_q, best_a = -float('inf'), 0
#         for a in range(num_actions):
#             q = sum(p * (r + gamma * V_values.get(s_next, 0)) for s_next, r, p in transitions[s][a])
#             if q > max_q:
#                 max_q, best_a = q, a
#         policy[s] = best_a

#     return V_values, policy

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
#     parser.add_argument('--policy', default=None)
#     args = parser.parse_args()

#     transitions, num_states, num_actions, end_states, gamma = parse_mdp(args.mdp)

#     if args.policy:
#         with open(args.policy, 'r') as f:
#             policy = list(map(int, f.read().split()))
#         V = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)[0]
#         optimal_policy = policy
#     else:
#         if args.algorithm == 'hpi':
#             V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
#         else:
#             V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

#     if len(optimal_policy) != num_states:
#         optimal_policy = [0] * num_states

#     for s in range(num_states):
#         value = round(V.get(s, 0.000000), 6)  # 🔥 Now V is a dictionary, so `.get()` works
#         action = optimal_policy[s] if s not in end_states else 0
#         print(f"{value:.6f} {action}")

# if __name__ == "__main__":
#     main()





























# import argparse
# import numpy as np
# from pulp import *

# def parse_mdp(file_path):
#     """Reads an MDP file and extracts the states, actions, transitions, and other parameters."""
#     transitions = {}
#     end_states = set()
#     gamma = 0.0
#     num_states = 0
#     num_actions = 0

#     with open(file_path, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if not line:
#                 continue
#             parts = line.split()
#             if parts[0] == 'numStates':
#                 num_states = int(parts[1])
#             elif parts[0] == 'numActions':
#                 num_actions = int(parts[1])
#                 transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
#             elif parts[0] == 'end' and len(parts) > 1:
#                 end_states = set(map(int, parts[1:]))
#             elif parts[0] == 'transition':
#                 s1, ac, s2 = map(int, parts[1:4])
#                 r, p = float(parts[4]), float(parts[5])
#                 transitions[s1][ac].append((s2, r, p))
#             elif parts[0] == 'mdptype':
#                 mdptype = parts[1]
#             elif parts[0] == 'discount':
#                 gamma = float(parts[1])

#     return transitions, num_states, num_actions, end_states, gamma

# def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Howard's Policy Iteration."""
#     policy = [0] * num_states
#     V = np.zeros(num_states, dtype=np.float64)

#     while True:
#         V_prev = np.copy(V)
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             a = policy[s]
#             V[s] = sum(p * (r + gamma * V_prev[s_next]) for s_next, r, p in transitions[s][a])
#         if np.max(np.abs(V - V_prev)) < 1e-10:
#             break

#         new_policy = policy.copy()
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             max_q, best_a = -float('inf'), 0
#             for a in range(num_actions):
#                 q = sum(p * (r + gamma * V[s_next]) for s_next, r, p in transitions[s][a])
#                 if q > max_q:
#                     max_q, best_a = q, a
#             new_policy[s] = best_a

#         if policy == new_policy:
#             break
#         policy = new_policy

#     return V, policy

# def linear_programming(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Linear Programming."""
#     prob = LpProblem("MDP_LP", LpMinimize)
#     V_vars = {s: LpVariable(f"V_{s}", cat='Continuous') for s in range(num_states)}

#     # Ensure terminal states have value V(s) = 0
#     for s in end_states:
#         prob += V_vars[s] == 0

#     # Add Bellman constraints for non-terminal states
#     for s in range(num_states):
#         if s in end_states:
#             continue
#         for a in range(num_actions):
#             prob += (V_vars[s] >= sum(p * (r + gamma * V_vars[s_next])
#                                        for s_next, r, p in transitions[s][a]))

#     prob.solve(PULP_CBC_CMD(msg=False))  # Disable solver messages

#     if prob.status != 1:
#         return {s: 0.0 for s in range(num_states)}, [0] * num_states

#     V_values = {s: value(V_vars[s]) for s in range(num_states)}
#     policy = [0] * num_states

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         max_q, best_a = -float('inf'), 0
#         for a in range(num_actions):
#             q = sum(p * (r + gamma * V_values.get(s_next, 0)) for s_next, r, p in transitions[s][a])
#             if q > max_q:
#                 max_q, best_a = q, a
#         policy[s] = best_a

#     return V_values, policy

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
#     parser.add_argument('--policy', default=None)
#     args = parser.parse_args()

#     transitions, num_states, num_actions, end_states, gamma = parse_mdp(args.mdp)

#     if args.policy:
#         with open(args.policy, 'r') as f:
#             policy = list(map(int, f.read().split()))
#         V = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)[0]
#         optimal_policy = policy
#     else:
#         if args.algorithm == 'hpi':
#             V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
#         else:
#             V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

#     if len(optimal_policy) != num_states:
#         optimal_policy = [0] * num_states

#     for s in range(num_states):
#         value = round(V.get(s, 0.000000), 6)
#         action = optimal_policy[s] if s not in end_states else 0
#         print(f"{value:.6f} {action}")

# if __name__ == "__main__":
#     main()




































# import argparse
# import numpy as np
# from pulp import *

# def parse_mdp(file_path):
#     """Reads an MDP file and extracts the states, actions, transitions, and other parameters."""
#     transitions = {}
#     end_states = set()
#     gamma = 0.0
#     num_states = 0
#     num_actions = 0

#     with open(file_path, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if not line:
#                 continue
#             parts = line.split()
#             if parts[0] == 'numStates':
#                 num_states = int(parts[1])
#             elif parts[0] == 'numActions':
#                 num_actions = int(parts[1])
#                 transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
#             elif parts[0] == 'end' and len(parts) > 1:
#                 end_states = set(map(int, parts[1:]))
#             elif parts[0] == 'transition':
#                 s1, ac, s2 = map(int, parts[1:4])
#                 r, p = float(parts[4]), float(parts[5])
#                 transitions[s1][ac].append((s2, r, p))
#             elif parts[0] == 'mdptype':
#                 mdptype = parts[1]
#             elif parts[0] == 'discount':
#                 gamma = float(parts[1])

#     return transitions, num_states, num_actions, end_states, gamma

# def evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma):
#     """Evaluates a given policy using Bellman equations."""
#     V = np.zeros(num_states, dtype=np.float64)

#     while True:
#         V_prev = np.copy(V)
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             a = policy[s]
#             V[s] = sum(p * (r + gamma * V_prev[s_next]) for s_next, r, p in transitions[s][a])
#         if np.max(np.abs(V - V_prev)) < 1e-10:
#             break

#     return {s: V[s] for s in range(num_states)}

# def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Howard's Policy Iteration."""
#     policy = [0] * num_states

#     while True:
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         new_policy = policy.copy()
#         policy_changed = False

#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             max_q, best_a = -float('inf'), 0
#             for a in range(num_actions):
#                 q = sum(p * (r + gamma * V[s_next]) for s_next, r, p in transitions[s][a])
#                 if q > max_q:
#                     max_q, best_a = q, a
#             if new_policy[s] != best_a:
#                 policy_changed = True
#                 new_policy[s] = best_a

#         if not policy_changed:
#             break
#         policy = new_policy

#     return V, policy

# def linear_programming(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Linear Programming (LP)."""
#     prob = LpProblem("MDP_LP", LpMinimize)
#     V_vars = {s: LpVariable(f"V_{s}", cat='Continuous') for s in range(num_states)}

#     prob += lpSum(V_vars[s] for s in range(num_states))

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         for a in range(num_actions):
#             prob += (V_vars[s] >= sum(p * (r + gamma * V_vars[s_next])
#                                        for s_next, r, p in transitions[s][a]))

#     prob.solve(PULP_CBC_CMD(msg=False))  # Disable solver messages

#     if prob.status != 1:
#         return {s: 0.0 for s in range(num_states)}, [0] * num_states

#     V_values = {s: value(V_vars[s]) for s in range(num_states)}
#     policy = [0] * num_states  # Ensure correct length

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         max_q, best_a = -float('inf'), 0
#         for a in range(num_actions):
#             q = sum(p * (r + gamma * V_values.get(s_next, 0)) for s_next, r, p in transitions[s][a])
#             if q > max_q:
#                 max_q, best_a = q, a
#         policy[s] = best_a

#     return V_values, policy

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
#     parser.add_argument('--policy', default=None)
#     args = parser.parse_args()

#     transitions, num_states, num_actions, end_states, gamma = parse_mdp(args.mdp)

#     if args.policy:
#         with open(args.policy, 'r') as f:
#             policy = list(map(int, f.read().split()))
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         optimal_policy = policy
#     else:
#         if args.algorithm == 'hpi':
#             V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
#         else:
#             V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

#     if len(optimal_policy) != num_states:
#         optimal_policy = [0] * num_states

#     for s in range(num_states):
#         value = round(V.get(s, 0.000000), 6)
#         action = optimal_policy[s] if s not in end_states else 0
#         print(f"{value:.6f} {action}")

# if __name__ == "__main__":
#     main()




































# import argparse
# import numpy as np
# from pulp import *
# from decimal import Decimal, getcontext

# getcontext().prec = 50  # Increase precision for floating-point calculations

# def parse_mdp(file_path):
#     """Reads an MDP file and extracts the states, actions, transitions, and other parameters."""
#     transitions = {}
#     end_states = set()
#     gamma = Decimal('0.0')
#     num_states = 0
#     num_actions = 0

#     with open(file_path, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if not line:
#                 continue
#             parts = line.split()
#             if parts[0] == 'numStates':
#                 num_states = int(parts[1])
#             elif parts[0] == 'numActions':
#                 num_actions = int(parts[1])
#                 transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
#             elif parts[0] == 'end' and len(parts) > 1:
#                 end_states = set(map(int, parts[1:]))
#             elif parts[0] == 'transition':
#                 s1, ac, s2 = map(int, parts[1:4])
#                 r, p = map(Decimal, parts[4:6])
#                 transitions[s1][ac].append((s2, r, p))
#             elif parts[0] == 'mdptype':
#                 mdptype = parts[1]
#             elif parts[0] == 'discount':
#                 gamma = Decimal(parts[1])

#     return transitions, num_states, num_actions, end_states, gamma

# def evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma):
#     """Evaluates a given policy using Bellman equations with high precision."""
#     V = np.zeros(num_states, dtype=np.float64)

#     while True:
#         V_prev = np.copy(V)
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             a = policy[s]
#             V[s] = sum(float(p * (r + gamma * Decimal(V_prev[s_next]))) for s_next, r, p in transitions[s][a])
#         if np.max(np.abs(V - V_prev)) < 1e-10:  # Use stricter convergence threshold
#             break

#     return {s: V[s] for s in range(num_states)}

# def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Howard's Policy Iteration with improved precision."""
#     policy = [0] * num_states

#     while True:
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         new_policy = policy.copy()
#         policy_changed = False

#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             max_q, best_a = -float('inf'), 0
#             for a in range(num_actions):
#                 q = sum(float(p * (r + gamma * Decimal(V[s_next]))) for s_next, r, p in transitions[s][a])
#                 if q > max_q:
#                     max_q, best_a = q, a
#             if new_policy[s] != best_a:
#                 policy_changed = True
#                 new_policy[s] = best_a

#         if not policy_changed:
#             break
#         policy = new_policy

#     return V, policy

# def linear_programming(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Linear Programming with high precision."""
#     prob = LpProblem("MDP_LP", LpMinimize)
#     V_vars = {s: LpVariable(f"V_{s}", cat='Continuous') for s in range(num_states)}

#     prob += lpSum([V_vars[s] for s in range(num_states)])

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         for a in range(num_actions):
#             prob += (V_vars[s] >= sum(float(p * (r + gamma * Decimal(V_vars[s_next])))
#                                        for s_next, r, p in transitions[s][a]))

#     prob.solve(PULP_CBC_CMD(msg=False))  # Disable solver messages

#     if prob.status != 1:
#         return {s: 0.0 for s in range(num_states)}, [0] * num_states

#     V_values = {s: float(value(V_vars[s])) for s in range(num_states)}
#     policy = [0] * num_states  # Ensure correct length

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         max_q, best_a = -float('inf'), 0
#         for a in range(num_actions):
#             q = sum(float(p * (r + gamma * Decimal(V_values.get(s_next, 0)))) for s_next, r, p in transitions[s][a])
#             if q > max_q:
#                 max_q, best_a = q, a
#         policy[s] = best_a

#     return V_values, policy

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
#     parser.add_argument('--policy', default=None)
#     args = parser.parse_args()

#     transitions, num_states, num_actions, end_states, gamma = parse_mdp(args.mdp)

#     if args.policy:
#         with open(args.policy, 'r') as f:
#             policy = list(map(int, f.read().split()))
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         optimal_policy = policy
#     else:
#         if args.algorithm == 'hpi':
#             V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
#         else:
#             V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

#     # Ensure policy list is the correct length
#     if len(optimal_policy) != num_states:
#         optimal_policy = [0] * num_states

#     # Correct output format: V*(s) π*(s)
#     for s in range(num_states):
#         value = round(V.get(s, 0.000000), 6)  # Force rounding to exactly 6 decimal places
#         action = optimal_policy[s] if s not in end_states else 0
#         print(f"{value:.6f} {action}")

# if __name__ == "__main__":
#     main()













# import argparse
# import numpy as np
# from pulp import *

# def parse_mdp(file_path):
#     """Reads an MDP file and extracts the states, actions, transitions, and other parameters."""
#     transitions = {}
#     end_states = set()
#     gamma = 0.0
#     num_states = 0
#     num_actions = 0

#     with open(file_path, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if not line:
#                 continue
#             parts = line.split()
#             if parts[0] == 'numStates':
#                 num_states = int(parts[1])
#             elif parts[0] == 'numActions':
#                 num_actions = int(parts[1])
#                 transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
#             elif parts[0] == 'end' and len(parts) > 1:
#                 end_states = set(map(int, parts[1:]))
#             elif parts[0] == 'transition':
#                 s1, ac, s2 = map(int, parts[1:4])
#                 r, p = map(float, parts[4:6])
#                 transitions[s1][ac].append((s2, r, p))
#             elif parts[0] == 'mdptype':
#                 mdptype = parts[1]
#             elif parts[0] == 'discount':
#                 gamma = float(parts[1])

#     return transitions, num_states, num_actions, end_states, gamma

# def evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma):
#     """Evaluates a given policy using Bellman equations."""
#     V = np.zeros(num_states)

#     while True:
#         V_prev = np.copy(V)
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             a = policy[s]
#             V[s] = sum(p * (r + gamma * V_prev[s_next]) for s_next, r, p in transitions[s][a])
#         if np.max(np.abs(V - V_prev)) < 1e-6:
#             break

#     return {s: V[s] for s in range(num_states)}

# def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Howard's Policy Iteration."""
#     policy = [0] * num_states

#     while True:
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         new_policy = policy.copy()
#         policy_changed = False

#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             max_q, best_a = -float('inf'), 0
#             for a in range(num_actions):
#                 q = sum(p * (r + gamma * V[s_next]) for s_next, r, p in transitions[s][a])
#                 if q > max_q:
#                     max_q, best_a = q, a
#             if new_policy[s] != best_a:
#                 policy_changed = True
#                 new_policy[s] = best_a

#         if not policy_changed:
#             break
#         policy = new_policy

#     return V, policy

# def linear_programming(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Linear Programming."""
#     prob = LpProblem("MDP_LP", LpMinimize)
#     V_vars = {s: LpVariable(f"V_{s}", cat='Continuous') for s in range(num_states)}

#     prob += lpSum([V_vars[s] for s in range(num_states)])

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         for a in range(num_actions):
#             prob += (V_vars[s] >= sum(p * (r + gamma * V_vars[s_next])
#                                        for s_next, r, p in transitions[s][a]))

#     prob.solve(PULP_CBC_CMD(msg=False))  # Disable solver messages

#     if prob.status != 1:
#         return {s: 0.0 for s in range(num_states)}, [0] * num_states

#     V_values = {s: value(V_vars[s]) for s in range(num_states)}
#     policy = [0] * num_states  # Ensure correct length

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         max_q, best_a = -float('inf'), 0
#         for a in range(num_actions):
#             q = sum(p * (r + gamma * V_values.get(s_next, 0)) for s_next, r, p in transitions[s][a])
#             if q > max_q:
#                 max_q, best_a = q, a
#         policy[s] = best_a

#     return V_values, policy

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
#     parser.add_argument('--policy', default=None)
#     args = parser.parse_args()

#     transitions, num_states, num_actions, end_states, gamma = parse_mdp(args.mdp)

#     if args.policy:
#         with open(args.policy, 'r') as f:
#             policy = list(map(int, f.read().split()))
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         optimal_policy = policy
#     else:
#         if args.algorithm == 'hpi':
#             V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
#         else:
#             V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

#     # Ensure policy list is the correct length
#     if len(optimal_policy) != num_states:
#         optimal_policy = [0] * num_states

#     # Correct output format: V*(s) π*(s)
#     for s in range(num_states):
#         value = V.get(s, 0.000000)  # Default 0 if missing
#         action = optimal_policy[s] if s not in end_states else 0
#         print(f"{value:.6f} {action}")

# if __name__ == "__main__":
#     main()































# import argparse
# import numpy as np
# from pulp import *

# def parse_mdp(file_path):
#     """Reads an MDP file and extracts the states, actions, transitions, and other parameters."""
#     transitions = {}
#     end_states = set()
#     gamma = 0.0
#     mdptype = ''
#     num_states = 0
#     num_actions = 0

#     with open(file_path, 'r') as f:
#         for line in f:
#             line = line.strip()
#             if not line:
#                 continue
#             parts = line.split()
#             if parts[0] == 'numStates':
#                 num_states = int(parts[1])
#             elif parts[0] == 'numActions':
#                 num_actions = int(parts[1])
#                 transitions = {s: {a: [] for a in range(num_actions)} for s in range(num_states)}
#             elif parts[0] == 'end' and len(parts) > 1:
#                 end_states = set(map(int, parts[1:]))
#             elif parts[0] == 'transition':
#                 s1 = int(parts[1])
#                 ac = int(parts[2])
#                 s2 = int(parts[3])
#                 r = float(parts[4])
#                 p = float(parts[5])
#                 transitions[s1][ac].append((s2, r, p))
#             elif parts[0] == 'mdptype':
#                 mdptype = parts[1]
#             elif parts[0] == 'discount':
#                 gamma = float(parts[1])

#     return transitions, num_states, num_actions, end_states, mdptype, gamma

# def evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma):
#     """Evaluates a given policy using Bellman equations."""
#     non_terminal = [s for s in range(num_states) if s not in end_states]
#     if not non_terminal:
#         return {s: 0.0 for s in range(num_states)}

#     n = len(non_terminal)
#     A = np.zeros((n, n))
#     B = np.zeros(n)
#     s_to_idx = {s: i for i, s in enumerate(non_terminal)}

#     for i, s in enumerate(non_terminal):
#         a = policy[s]
#         A[i][i] = 1.0
#         rhs = 0.0
#         for (s_next, r, p_trans) in transitions[s][a]:
#             rhs += p_trans * r
#             if s_next in end_states:
#                 continue
#             if s_next in s_to_idx:
#                 j = s_to_idx[s_next]
#                 A[i][j] -= gamma * p_trans
#         B[i] = rhs

#     try:
#         solution = np.linalg.solve(A, B)
#     except np.linalg.LinAlgError:
#         solution = np.zeros(n)

#     V = {s: 0.0 for s in end_states}
#     for i, s in enumerate(non_terminal):
#         V[s] = solution[i]
#     return V

# def howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Howard's Policy Iteration."""
#     policy = [0] * num_states
#     while True:
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         new_policy = policy.copy()
#         policy_changed = False
#         for s in range(num_states):
#             if s in end_states:
#                 continue
#             max_q = -float('inf')
#             best_a = 0
#             for a in range(num_actions):
#                 q = 0.0
#                 for (s_next, r, p) in transitions[s][a]:
#                     if s_next in end_states:
#                         q += p * r
#                     else:
#                         q += p * (r + gamma * V[s_next])
#                 if q > max_q or (q == max_q and a < best_a):
#                     max_q = q
#                     best_a = a
#             if new_policy[s] != best_a:
#                 policy_changed = True
#                 new_policy[s] = best_a
#         if not policy_changed:
#             break
#         policy = new_policy

#     return V, policy

# def linear_programming(transitions, num_states, num_actions, end_states, gamma):
#     """Computes the optimal policy using Linear Programming."""
#     prob = LpProblem("MDP_LP", LpMinimize)
#     V_vars = {s: LpVariable(f"V_{s}", cat='Continuous') for s in range(num_states)}

#     prob += lpSum([V_vars[s] for s in range(num_states)])

#     for s in range(num_states):
#         if s in end_states:
#             continue
#         for a in range(num_actions):
#             prob += (V_vars[s] >= sum(p * (r + gamma * V_vars[s_next])
#                                        for (s_next, r, p) in transitions[s][a]))

#     prob.solve(PULP_CBC_CMD(msg=False))  # Disable solver messages for clean output

#     if prob.status != 1:
#         return {}, []

#     V_values = {s: value(V_vars[s]) for s in range(num_states)}
#     policy = [0] * num_states

#     for s in range(num_states):
#         if s in end_states:
#             policy[s] = 0
#             continue
#         max_q = -float('inf')
#         best_a = 0
#         for a in range(num_actions):
#             q = 0.0
#             for (s_next, r, p) in transitions[s][a]:
#                 if s_next in end_states:
#                     q += p * r
#                 else:
#                     q += p * (r + gamma * V_values[s_next])
#             if q > max_q or (q == max_q and a < best_a):
#                 max_q = q
#                 best_a = a
#         policy[s] = best_a

#     return V_values, policy

# def main():
#     parser = argparse.ArgumentParser()
#     parser.add_argument('--mdp', required=True)
#     parser.add_argument('--algorithm', choices=['hpi', 'lp'], default='hpi')
#     parser.add_argument('--policy', default=None)
#     args = parser.parse_args()

#     transitions, num_states, num_actions, end_states, mdptype, gamma = parse_mdp(args.mdp)

#     if args.policy:
#         with open(args.policy, 'r') as f:
#             policy = list(map(int, f.read().split()))
#         V = evaluate_policy(policy, transitions, num_states, num_actions, end_states, gamma)
#         optimal_policy = policy
#     else:
#         if args.algorithm == 'hpi':
#             V, optimal_policy = howard_policy_iteration(transitions, num_states, num_actions, end_states, gamma)
#         else:
#             V, optimal_policy = linear_programming(transitions, num_states, num_actions, end_states, gamma)

#     # **Final Corrected Output Format**
#     for s in range(num_states):
#         value = V.get(s, 0.000000)  # Default to 0 for missing values
#         action = optimal_policy[s] if s not in end_states else 0
#         print(f"{value:.6f} {action}")

# if __name__ == "__main__":
#     main()















# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def create_state_map(grid):
#     state_map = {}
#     state_id = 0
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             # Process all cells except walls
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1
#     return state_map

# def parse_test_case(test_case):
#     agent_pos = None
#     has_key = 0  # Default to no key
#     direction_map = {'>':0, '^':1, '<':2, 'v':3}
    
#     lines = test_case.strip().split('\n')
#     for row_idx, line in enumerate(lines):
#         if not line.strip():
#             continue
#         row = line.strip().split()
#         for j, cell in enumerate(row):
#             if cell in direction_map:
#                 agent_pos = (row_idx, j, direction_map[cell])
#             if cell == 'k':
#                 has_key = 1  # Key exists in test case
#     return agent_pos, has_key

# def decode(mdp_file, policy_file, gridworld_file):
#     # Rebuild state map from original gridworld
#     grid = load_gridworld(gridworld_file)
#     state_map = create_state_map(grid)
    
#     # Load policy with robust parsing
#     policy = {}
#     with open(policy_file, 'r') as f:
#         for line_num, line in enumerate(f):
#             parts = line.strip().split()
#             if len(parts) < 2:
#                 continue
#             try:
#                 state = int(parts[0])
#                 action = int(float(parts[1]))  # Handle float actions
#                 if 0 <= action <= 3:
#                     policy[state] = action
#             except (ValueError, IndexError):
#                 continue

#     # Process test cases
#     with open(gridworld_file, 'r') as f:
#         test_cases = f.read().split('Testcase')[1:]  # Skip empty first split

#     output = []
#     for test in test_cases:
#         agent_info, key_in_grid = parse_test_case(test)
#         has_key = 0 if key_in_grid else 1  # Flip logic: 1=has key
        
#         if not agent_info:
#             output.append("0")
#             continue
            
#         i, j, direction = agent_info
#         # Validate grid bounds
#         if i >= len(grid) or j >= len(grid[i]):
#             output.append("0")
#             continue
            
#         state_key = (i, j, direction, has_key)
#         state_id = state_map.get(state_key, -1)
        
#         action = policy.get(state_id, 0)
#         output.append(str(action))

#     # Pad missing outputs to match expected count
#     expected_length = len(test_cases)
#     while len(output) < expected_length:
#         output.append("0")
    
#     print(' '.join(output[:expected_length]))

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--mdp", required=True)
#     parser.add_argument("--value-policy", required=True)
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     decode(args.mdp, args.value_policy, args.gridworld)




























# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def create_state_map(grid):
#     state_map = {}
#     state_id = 0
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1
#     return state_map

# def parse_test_case(test_case):
#     agent_pos = None
#     has_key = 1  # Assume agent has key
#     direction_map = {'>':0, '^':1, '<':2, 'v':3}
    
#     lines = test_case.strip().split('\n')
#     for row_idx, line in enumerate(lines):
#         row = line.strip().split()
#         if not row:
#             continue
#         for j, cell in enumerate(row):
#             if cell in direction_map:
#                 agent_pos = (row_idx, j, direction_map[cell])
#             if cell == 'k':
#                 has_key = 0  # Key exists, agent hasn't collected it
#     return agent_pos, has_key

# def decode(mdp_file, policy_file, gridworld_file):
#     # Recreate state map from original gridworld
#     grid = load_gridworld(gridworld_file)
#     state_map = create_state_map(grid)
    
#     # Load policy
#     policy = {}
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 try:
#                     state = int(parts[0])
#                     action = int(float(parts[1]))
#                     policy[state] = action
#                 except ValueError:
#                     continue

#     # Process test cases
#     with open(gridworld_file, 'r') as f:
#         content = f.read().split('Testcase')[1:]

#     output = []
#     for test_case in content:
#         agent_info, has_key = parse_test_case(test_case)
#         if not agent_info:
#             output.append("0")
#             continue
            
#         i, j, direction = agent_info
#         # Validate coordinates against original grid
#         if i >= len(grid) or j >= len(grid[i]) or grid[i][j] == 'W':
#             output.append("0")
#             continue
            
#         state_key = (i, j, direction, has_key)
#         state_id = state_map.get(state_key, -1)
        
#         action = policy.get(state_id, 0)
#         action = max(0, min(3, action))
#         output.append(str(action))

#     print(' '.join(output))

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--mdp", required=True)
#     parser.add_argument("--value-policy", required=True)
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     decode(args.mdp, args.value_policy, args.gridworld)




































# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def create_state_map(grid):
#     state_map = {}
#     state_id = 0
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1
#     return state_map

# def parse_test_case(test_case):
#     agent_pos = None
#     has_key = 0
#     direction_map = {'>':0, '^':1, '<':2, 'v':3}
    
#     lines = test_case.strip().split('\n')
#     for row_idx, line in enumerate(lines):
#         row = line.strip().split()
#         if not row:
#             continue
#         for j, cell in enumerate(row):
#             if cell in direction_map:
#                 agent_pos = (row_idx, j, direction_map[cell])
#             if cell == 'k':
#                 has_key = 1
#     return agent_pos, has_key

# def decode(mdp_file, policy_file, gridworld_file):
#     # Recreate state map from original gridworld
#     grid = load_gridworld(gridworld_file)
#     state_map = create_state_map(grid)
    
#     # Load policy (handle float action values)
#     policy = {}
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 try:
#                     state = int(parts[0])
#                     action = int(float(parts[1]))  # Convert potential float to int
#                     policy[state] = action
#                 except ValueError:
#                     continue  # Skip invalid lines

#     # Process test cases
#     with open(gridworld_file, 'r') as f:
#         content = f.read().split('Testcase')[1:]

#     output = []
#     for test_case in content:
#         agent_info, has_key = parse_test_case(test_case)
#         if not agent_info:
#             output.append("0")
#             continue
            
#         i, j, direction = agent_info
#         state_key = (i, j, direction, has_key)
#         state_id = state_map.get(state_key, -1)
        
#         # Ensure valid action (0-3)
#         action = policy.get(state_id, 0)
#         output.append(str(max(0, min(3, action))))  # Clamp to valid actions

#     print(' '.join(output))

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--mdp", required=True)
#     parser.add_argument("--value-policy", required=True)
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     decode(args.mdp, args.value_policy, args.gridworld)




























# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def create_state_map(grid):
#     state_map = {}
#     state_id = 0
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1
#     return state_map

# def parse_test_case(test_case):
#     agent_pos = None
#     has_key = 0
#     direction_map = {'>':0, '^':1, '<':2, 'v':3}
    
#     for line in test_case.strip().split('\n'):
#         row = line.strip().split()
#         if not row:
#             continue
#         for j, cell in enumerate(row):
#             if cell in direction_map:
#                 agent_pos = (int(line.metadata['row']), j, direction_map[cell])
#             if cell == 'k':
#                 has_key = 1
#     return agent_pos, has_key

# def decode(mdp_file, policy_file, gridworld_file):
#     # Recreate state map from original gridworld
#     grid = load_gridworld(gridworld_file)
#     state_map = create_state_map(grid)
    
#     # Load policy
#     policy = {}
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy[int(parts[0])] = int(parts[1])

#     # Process test cases
#     with open(gridworld_file, 'r') as f:
#         content = f.read().split('Testcase')[1:]

#     output = []
#     for test_case in content:
#         agent_info, has_key = parse_test_case(test_case)
#         if not agent_info:
#             output.append("0")
#             continue
            
#         i, j, direction = agent_info
#         state_key = (i, j, direction, has_key)
#         state_id = state_map.get(state_key, -1)
        
#         output.append(str(policy.get(state_id, 0)))

#     print(' '.join(output))

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--mdp", required=True)
#     parser.add_argument("--value-policy", required=True)
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     decode(args.mdp, args.value_policy, args.gridworld)






































# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def create_state_map(grid):
#     state_map = {}
#     state_id = 0
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1
#     return state_map

# def parse_test_case(test_case):
#     grid = []
#     agent_pos = None
#     direction_map = {'>':0, '^':1, '<':2, 'v':3}
#     has_key = 0
    
#     for line in test_case.strip().split('\n'):
#         row = line.strip().split()
#         if not row:
#             continue
#         grid.append(row)
#         for j, cell in enumerate(row):
#             if cell in direction_map:
#                 agent_pos = (len(grid)-1, j, direction_map[cell])
#             if cell == 'k':
#                 has_key = 1
#     return agent_pos, has_key, grid

# def decode(mdp_file, policy_file, test_file):
#     # Load original gridworld to recreate state map
#     original_grid = load_gridworld(test_file)
#     state_map = create_state_map(original_grid)
    
#     # Load policy
#     policy = {}
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy[int(parts[0])] = int(parts[1])

#     # Process test cases
#     with open(test_file, 'r') as f:
#         test_cases = f.read().split('Testcase')[1:]

#     output = []
#     for test in test_cases:
#         agent_info, has_key, _ = parse_test_case(test)
#         if not agent_info:
#             output.append("0")
#             continue
            
#         i, j, direction = agent_info
#         state_key = (i, j, direction, has_key)
#         state_id = state_map.get(state_key, -1)
        
#         if state_id == -1 or state_id not in policy:
#             output.append("0")
#         else:
#             output.append(str(policy[state_id]))

#     print(' '.join(output))

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--mdp", required=True)
#     parser.add_argument("--value-policy", required=True)
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     decode(args.mdp, args.value_policy, args.gridworld)




















































# import argparse

# def parse_test_case(test_case):
#     grid = []
#     agent_state = None
#     has_key = 0
#     direction_map = {'>': 0, '^': 1, '<': 2, 'v': 3}
    
#     for line in test_case.strip().split('\n'):
#         row = line.strip().split()
#         if not row:
#             continue
#         grid.append(row)
#         for j, cell in enumerate(row):
#             if cell in direction_map:
#                 agent_state = (len(grid)-1, j, direction_map[cell])
#             if cell == 'k':
#                 has_key = 1  # Key exists in current test case
#     return agent_state, has_key

# def calculate_state_id(agent_pos, has_key, grid_size):
#     i, j, direction = agent_pos
#     states_per_cell = 4 * 2  # 4 directions * 2 key states
#     cell_id = (i * grid_size + j) * states_per_cell
#     return cell_id + direction * 2 + has_key

# def decode(mdp_file, policy_file, test_file):
#     # Load policy
#     policy = {}
#     with open(policy_file, 'r') as f:
#         for line in f:
#             parts = line.strip().split()
#             if len(parts) >= 2:
#                 policy[int(parts[0])] = int(parts[1])

#     # Process test cases
#     with open(test_file, 'r') as f:
#         test_cases = f.read().split('Testcase')[1:]

#     grid_size = 15  # Assuming standard grid size from problem description
#     output = []
    
#     for test in test_cases:
#         agent_state, has_key = parse_test_case(test)
#         if not agent_state:
#             output.append("0")
#             continue
            
#         state_id = calculate_state_id(agent_state, has_key, grid_size)
#         output.append(str(policy.get(state_id, 0)))

#     print(' '.join(output))

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--mdp", required=True)
#     parser.add_argument("--value-policy", required=True)
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     decode(args.mdp, args.value_policy, args.gridworld)































































# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def encode_gridworld(gridworld_file):
#     grid = load_gridworld(gridworld_file)
#     if not grid:
#         raise ValueError("Empty gridworld file")
    
#     state_map = {}
#     terminal_states = set()
#     state_id = 0

#     # Create state mappings
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':  # Terminal states
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         terminal_states.add(state_id)
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1

#     num_states = len(state_map)
#     num_actions = 4
#     transitions = []

#     # Generate transitions
#     for (i, j, d, k) in state_map:
#         s = state_map[(i, j, d, k)]
#         cell = grid[i][j]
        
#         if s in terminal_states:
#             continue

#         for action in range(num_actions):
#             if action == 0:  # Move forward
#                 # Block move through closed door
#                 if cell == 'd' and k == 0:
#                     continue

#                 directions = [(0, 1), (-1, 0), (0, -1), (1, 0)]
#                 di, dj = directions[d]
                
#                 possible_steps = []
#                 current_i, current_j = i, j
#                 for _ in range(3):
#                     current_i += di
#                     current_j += dj
#                     if (0 <= current_i < len(grid)) and \
#                        (0 <= current_j < len(grid[current_i])) and \
#                        grid[current_i][current_j] != 'W':
#                         possible_steps.append((current_i, current_j))
#                     else:
#                         break

#                 if not possible_steps:
#                     continue

#                 # Normalize probabilities
#                 probs = [0.5, 0.3, 0.2][:len(possible_steps)]
#                 total = sum(probs)
#                 probs = [p/total for p in probs]

#                 for idx, (ni, nj) in enumerate(possible_steps):
#                     new_k = 1 if grid[ni][nj] == 'k' else k
#                     s_next = state_map[(ni, nj, d, new_k)]
#                     transitions.append(f"transition {s} {action} {s_next} -1 {probs[idx]:.6f}")

#             else:  # Turn actions
#                 new_dirs = []
#                 probs = []
#                 if action == 1:  # Turn left
#                     new_dirs = [(d-1)%4]
#                     probs = [1.0]
#                 elif action == 2:  # Turn right
#                     new_dirs = [(d+1)%4]
#                     probs = [1.0]
#                 else:  # Turn around
#                     new_dirs = [(d+2)%4]
#                     probs = [1.0]

#                 for nd, p in zip(new_dirs, probs):
#                     s_next = state_map[(i, j, nd, k)]
#                     transitions.append(f"transition {s} {action} {s_next} -1 {p:.6f}")

#     print(f"numStates {num_states}")
#     print(f"numActions {num_actions}")
#     print(f"end {' '.join(map(str, terminal_states))}")
#     print('\n'.join(transitions))
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     encode_gridworld(args.gridworld)

































# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def encode_gridworld(gridworld_file):
#     grid = load_gridworld(gridworld_file)
#     if not grid:
#         raise ValueError("Empty gridworld file")
    
#     state_map = {}
#     terminal_states = set()
#     state_id = 0

#     # Create state mappings
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':  # Terminal states
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         terminal_states.add(state_id)
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1

#     num_states = len(state_map)
#     num_actions = 4
#     transitions = []

#     # Generate transitions
#     for (i, j, d, k) in state_map:
#         s = state_map[(i, j, d, k)]
#         cell = grid[i][j]
        
#         # Skip terminal states
#         if s in terminal_states:
#             continue

#         # Block door without key
#         if cell == 'd' and k == 0:
#             continue

#         for action in range(num_actions):
#             if action == 0:  # Move forward
#                 directions = [(0, 1), (-1, 0), (0, -1), (1, 0)]
#                 di, dj = directions[d]
                
#                 possible_steps = []
#                 current_i, current_j = i, j
#                 for _ in range(3):
#                     current_i += di
#                     current_j += dj
#                     if (0 <= current_i < len(grid)) and \
#                        (0 <= current_j < len(grid[current_i])) and \
#                        grid[current_i][current_j] != 'W':
#                         possible_steps.append((current_i, current_j))
#                     else:
#                         break

#                 if not possible_steps:
#                     continue

#                 # Normalize probabilities
#                 probs = [0.5, 0.3, 0.2][:len(possible_steps)]
#                 total = sum(probs)
#                 probs = [p/total for p in probs]

#                 for idx, (ni, nj) in enumerate(possible_steps):
#                     new_k = 1 if grid[ni][nj] == 'k' else k
#                     s_next = state_map[(ni, nj, d, new_k)]
#                     transitions.append(f"transition {s} {action} {s_next} -1 {probs[idx]:.6f}")

#             else:  # Turn actions
#                 new_dirs = []
#                 probs = []
#                 if action == 1:  # Turn left
#                     new_dirs = [(d-1)%4]
#                     probs = [1.0]
#                 elif action == 2:  # Turn right
#                     new_dirs = [(d+1)%4]
#                     probs = [1.0]
#                 else:  # Turn around
#                     new_dirs = [(d+2)%4]
#                     probs = [1.0]

#                 for nd, p in zip(new_dirs, probs):
#                     s_next = state_map[(i, j, nd, k)]
#                     transitions.append(f"transition {s} {action} {s_next} -1 {p:.6f}")

#     print(f"numStates {num_states}")
#     print(f"numActions {num_actions}")
#     print(f"end {' '.join(map(str, terminal_states))}")
#     print('\n'.join(transitions))
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     encode_gridworld(args.gridworld)
















































# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def encode_gridworld(gridworld_file):
#     grid = load_gridworld(gridworld_file)
#     if not grid:
#         raise ValueError("Empty gridworld file")
    
#     state_map = {}
#     terminal_states = set()
#     state_id = 0

#     # Create state mappings
#     for i in range(len(grid)):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             if cell == 'g':
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         terminal_states.add(state_id)
#                         state_id += 1
#                 continue
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1

#     # ... (rest of encoder.py remains same as previous correct version)
#     # Full encoder code should be here as earlier


















































# import argparse

# def load_gridworld(file_path):
#     grid = []
#     with open(file_path, 'r') as f:
#         for line in f:
#             row = line.strip().split()
#             if row:
#                 grid.append(row)
#     return grid

# def encode_gridworld(gridworld_file):
#     grid = load_gridworld(gridworld_file)
#     if not grid:
#         raise ValueError("Empty gridworld file")
    
#     size = len(grid)
#     state_map = {}
#     terminal_states = set()
#     state_id = 0

#     # Create state mappings
#     for i in range(size):
#         for j in range(len(grid[i])):
#             cell = grid[i][j]
#             if cell == 'W':
#                 continue
#             # Handle goal cells
#             if cell == 'g':
#                 for direction in range(4):
#                     for has_key in [0, 1]:
#                         state_map[(i, j, direction, has_key)] = state_id
#                         terminal_states.add(state_id)
#                         state_id += 1
#                 continue
#             # Regular cells
#             for direction in range(4):
#                 for has_key in [0, 1]:
#                     state_map[(i, j, direction, has_key)] = state_id
#                     state_id += 1

#     num_states = len(state_map)
#     num_actions = 4
#     transitions = []

#     # Generate transitions
#     for (i, j, d, k) in state_map:
#         s = state_map[(i, j, d, k)]
#         cell = grid[i][j]
        
#         # Skip terminal states
#         if s in terminal_states:
#             continue

#         # Block door without key
#         if cell == 'd' and k == 0:
#             continue

#         for action in range(num_actions):
#             if action == 0:  # Move forward
#                 directions = [(0, 1), (-1, 0), (0, -1), (1, 0)]
#                 di, dj = directions[d]
                
#                 possible_steps = []
#                 current_i, current_j = i, j
#                 for _ in range(3):  # Max 3 steps
#                     current_i += di
#                     current_j += dj
#                     if (0 <= current_i < size and 
#                         0 <= current_j < len(grid[current_i]) and 
#                         grid[current_i][current_j] != 'W'):
#                         possible_steps.append((current_i, current_j))
#                     else:
#                         break

#                 # Critical fix: Handle zero possible steps
#                 if not possible_steps:
#                     continue

#                 # Normalize probabilities
#                 probs = [0.5, 0.3, 0.2][:len(possible_steps)]
#                 total = sum(probs)
#                 probs = [p/total for p in probs]

#                 # Add transitions
#                 for idx, (ni, nj) in enumerate(possible_steps):
#                     new_k = 1 if grid[ni][nj] == 'k' else k
#                     s_next = state_map[(ni, nj, d, new_k)]
#                     transitions.append(f"transition {s} {action} {s_next} -1 {probs[idx]:.6f}")

#             else:  # Turn actions
#                 if action == 1:  # Turn left
#                     new_dirs = [(d-1)%4]
#                     probs = [1.0]  # Simplified for reliability
#                 elif action == 2:  # Turn right
#                     new_dirs = [(d+1)%4]
#                     probs = [1.0]
#                 else:  # Turn around
#                     new_dirs = [(d+2)%4]
#                     probs = [1.0]

#                 for nd, p in zip(new_dirs, probs):
#                     s_next = state_map[(i, j, nd, k)]
#                     transitions.append(f"transition {s} {action} {s_next} -1 {p:.6f}")

#     # Output MDP
#     print(f"numStates {num_states}")
#     print(f"numActions {num_actions}")
#     print(f"end {' '.join(map(str, terminal_states))}")
#     print('\n'.join(transitions))
#     print("mdptype episodic")
#     print("discount 1.0")

# if __name__ == "__main__":
#     parser = argparse.ArgumentParser()
#     parser.add_argument("--gridworld", required=True)
#     args = parser.parse_args()
#     encode_gridworld(args.gridworld)